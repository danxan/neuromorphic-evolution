The Integrated Information Theory (IIT) has been proposed as a mathematical way to understand consciousness.
Essentially, it revolves around analysing the phenomenology of a system.
That is, how a causal structure experiences an environment.
The theory tries to assume properties of consciousness (axioms), and from there it posulates the physical properties that must be necessary in a neural substrate hosting the system.
The causal structure is based on measures of how a system is able to integrate information, and the tools provided is the specification of a cause-effect structure (CES).
The amount of information is larger the higher the amount of possible states in the system. Integrated information is when there is no way to cut without loosing information.The CES is an unfolding of a model of the neural substrate, in the sense that the model is cut in every possible way (imagine cutting a network of nodes).
The CES is mapped to the properties of experience, and the CES can be quantified by $\Phi$. \cite{oizumi_phenomenology_2014}

Although IIT might seem overly abstract, the first tangible result was published as a study on the question "Why does space feel the way it does?".
Here a model of the Visual Cortex 1 and 2 (V1 and V2) was cut into a CES, using the knowledge of the grid cells that have been proven to be important for localization \cite{haun_why_2019}.

The IIT is a central part of the related works of this essay, and thus, some parts need to be explained:
\section{Causal Structures}
\section{Conceptual Structures}

In this project, I hope to utilize IIT as a way to analyze the perception of automated agents, evolved as SNN animats on BrainScaleS. (See \vref{sect:agent}, \vref{sect:snn}, \vref{sect:neuromorphic}).
As the complexity and states of the animats is known, the animats can be analyzed.
This is a challenging task, which will be attempted near the end of the project.
