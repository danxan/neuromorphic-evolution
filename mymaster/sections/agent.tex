The manmade, intelligent autonomous agent would be different from a programme, in terms of it being able to operate like a free, thinking entity.
Where a programme follows certain rules, an autonomous agent would only be constrained by mechanisms analogous to our biological constraints.
It would be able to gradually evolve its perception, function and logic to match its experiences of a changing environment, and expand and explore its own cognitive abilities \cite{franklin_graesser_agents}
As Alan Turing points out, and as we have discussed earlier, this would simply not be possible with discrete-state logic-gate systems.
It was pointed out that discrete-state machines in the beginning of the current millenia would be able to fool a human for a very limited amount of time,
and this is certainly the case today \cite{computing_machine_intelligence_turing}.
The progress made in computational cognitive science is truly astonishing, where competence oriented agents are modeling advanced human abilities.
The agents often exhibit impressive performance, but they often lack in terms of general intelligence \cite{wilson_animat}.
The question remains whether the conservation of momentum will hold if other techniques are not explored.
One such technique is the artificial animal, the "animat", explored in detail by Stewart W. Wilson in 1985, and first proposed as the "child machine" by Alan Turing in 1950 \cite{wilson_animat} \cite{turing_computing_machine_intelligence}.

\subsection{Animat}
