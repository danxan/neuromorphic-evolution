This essay taps into a diverse set of research fields. The ambition is to scope the project down to a combination of this diverse knowledge that might bring a contribution to science. The most prominent topics are artificial intelligence, evolutionary computing, neuromorphic electronic systems, neurobiology, and consciousness theory.
These topics are, of course, all highly relevant in a philosophical discussion of artificial intelligence, which has become the main tag for this essay.

\paragraph{One experiment}, examined through the lenses of a couple of thinkers, would be the ideal fit for this project.
Which perspectives to analyze the experiment through is yet to be decided, but this chapter will propose an initial experiment:
To evolve SNN \vref{sect:snn} animats \vref{sect:agent} implemented on BrainScaleS, \vref{sect:bss} to play a falling blocks game.
The experiment would be an iterative replication of \cite{albantakis_evolution_2014} on BrainScaleS.
The experiment should provide a basis for comparison of systems, from implementation with logic gates to implementation with continuous variables to implementation on BrainScaleS.
The comparisons can provide various answers based on the perspectives chosen.

\subsection{Methods} in these experiments are chosen to provide a comparison of systems; Digital discrete, digital continuous, and mixed-signal continuous.
The discrete digital implementation includes both the game and the animat in Python, with the evolutionary algorithm replicating the one used in \cite{albantakis_evolution_2014}.
The continuous digital step has two parts. The first would be to implement the animat as an SNN in a simulator that has a fitting AdExp model \vref{sect:adexp}. This simulator would most likely be NEST \cite{fardet_nest_2020}, using PyNN \cite{davison_pynn_2009}. The second part would be to implement the game in PyNN
Finally, the accelerated timescale of BrainScaleS requires the mixed-signal continuous implementation of the experiment to have both the animat and the game in PyNN.
Additionally, the neural network animats would need a design that allows evolution, which requires certain compliances to hardware constraints.
The three different implementations of the same experiment will not have much value unless one tries to answer specific questions by the comparison.
The idea is that specific questions can be answered when needed if the results and configuration are ready to be replicated.

After each of the first, second, and third steps, there should be data of results and configurations that can be analyzed and re-run to produce metrics according to the perspectives chosen for the theoretical contribution.

\subsection{Perspectives}
\paragraph{From the perspective of efficiency in neuromorphic systems}, an animat approach could be interesting in terms of finding circuit designs that better utilize the characteristics of the architecture.
The BrainScaleS architecture carries several of the elements of the design that Carver Mead proposed, which are analog components and wafer-scale integration.
In theory, such a system should be efficient solving complex differential equations with only a few transistors, given the correct hardware configuration.
The apparent problem of neuromorphic systems is that they are hard to train. Ordinary methods are inefficient and may not utilize the strengths of the neuromorphic system.
As was proposed in \cite{schuman_evolutionary_2016}, methods from evolutionary computing allow for topological and qualitative changes to the networks that might utilize the characteristics of the transistors in a way that could not have been designed by humans.
Using noise as a resource \cite{maass_noise_2014}, by Wolfgang Maass, is an excellent example of unique transistor characteristics that could not have been done by design.
Comparing the various implementations that are in a simulation and on neuromorphic hardware, it might be possible to make a measure of efficiency.

\paragraph{From the perspective of applications of neuromorphic systems}, an animat approach seems like an attractive solution because of how the approach evolves systems that work well in an environment even though none of the underlying conceptual structures solves tasks that would seem necessary to succeed.
The opposite of the animat approach would be the competence oriented approach of training neural networks for particular tasks.
The nodes of ordinary neural networks used in machine learning today will produce one specific output per specific input, which makes competence oriented training a natural solution of choice.
The analog AdExp neurons \vref{sect:adexp} of BrainScaleS will produce different outputs based on the internal state of the specific node, which could be problematic noise in the competence oriented approach. However, this is a valuable resource for robustness and functional redundancy, which is the ability to perform the same function with different parts of the system.
An example of functional abundance is that a network can recognize cats, but when one of the parts in the network dies, there is another part that also recognizes cats.
Another example of possible achievements is when the nodes can produce different outputs is that the network could use fewer nodes to produce the same functionality or more.
An example would be that developers could train an ordinary ANN to perform well at the recognition of cats. However, the developers would then be quite sure that the same ANN would not perform well at finding punctuation errors in a text.
It would seem that this example is not as valid for networks on BrainScaleS, although it is likely that the various tasks that one network would be efficient at would not be as specific as the two tasks in the example above.
Following is a thought experiment of how animats would develop an essential blend of competencies that is hard to design.
Imagine a world-simulator that included sound, forces like gravity and friction, and objects of various shapes, functions, and colors.
Imagine then populating the world with animats that could manipulate the world, but that needed to survive.
The condition for survival could be that they needed to touch a certain number of red, round objects per day.
The color of the objects changes when touched by an animat, so being an efficient hunter of red orbs would undoubtedly be a matter of importance.
The specific competencies necessary for survival in this world is, of course, object recognition, color recognition, and efficient movement.
However, there might be other skills and finesses that play a difference, but that is not as obvious to a designer.
Following the reasoning above, the animat approach seems a viable method for finding applications for BrainScaleS.
The animat approach is a method for letting the agent find out which skills are necessary to complete the main task.
If the comparisons show that the animats have higher fitness on BrainScaleS, then this would probably help make suggestions as to how to make real-world applications with the BrainScaleS technology.

\paragraph{From the perspective of Integrated Information Theory}, an experiment involving the evolution of networks on analog components can be useful for validating parts of the theory.
There is an interesting corollary from IIT 3.0, saying that even though a neural network performs very complex functions, it could not be conscious if built in a simulation, \vref{sect:iit}. On an ordinary computer, functions that simulate neuronal activity are what represent the neurons of a network.
Neural networks on BrainScaleS are physical, where only a few analog components provide the functionality of each neuron and synapse, and the synapses also implement adaptive learning through plasticity \vref{sect:bss}.
As discussed in the same section, the on-wafer communication between neurons is continuous, highly connected, and dependent on the varying internal states of the components that carry the signals.
IIT supporters would generally deny that artificial intelligence based on the technology used today could be conscious but do not outright the same claims for the BrainScaleS system.
Additionally, BrainScaleS closely emulates biological neural networks, including the relationship between synapses and neurons when it comes to weakness or cell death.
Biological evolution proves that systems that individuals that are more robust to failure and adaptive to changing environments will make it more often than their peers.
Robustness and adaptiveness are traits that also follow systems considered highly integrated by IIT.
Given that BrainScaleS has a speedup factor of 10 000 compared to biological wall time, there is a possibility that evolution also is a component that can make a theoretical contribution to IIT.

\paragraph{From the perspective of Artificial Intelligence discussion}, the exploration of neuromorphic systems is interesting because the researchers intend their architectures to simulate the brain better.
Based on the history recapitalization of \vref{sect:intro} and \vref{sect:neuromorphic}, it may seem like many computing pioneers aimed at building a ``thinking machine.''
Modern information theory and computer architecture partly came from trying to replicate the form and function of human intelligence and the brain.
George Boole, the father of logic algebra, the mathematics that led to combinatorics and the transistor, was concerned with capturing human reasoning.
John von Neumann loosely based his architecture, the most popular of today, on analogies to neurons and the brain.
Alan Turing, who helped bring von Neumann architecture to the world, published works on artificial intelligence that still has a  direct influence on modern researchers.
Viewing history from this perspective, one may wonder if further development of computing itself requires that we continue to pursue the brain in terms of hardware.
Carver Mead, a professor on transistors, and a close friend of Gordon Moore, whom the famous ``Moore's law'' stems from, was the one who coined neuromorphic electronic systems.
Turing also proposed ways to develop and test artificial intelligence. One of those was the "Child-Machine," which later turned into the "Animat."
The animat has not turned out to be an effective way of developing artificial intelligence on arithmetic computers, which is nothing else than approximations of very complex functions.
There is no reason to believe that Turing, or anyone else from the past, could have found better answers to questions of today than the people asking the questions today.
However, there is reason to believe that a system could develop intelligence like a child does develop intelligence, given the right physical and mechanical conditions, and maybe BrainScaleS has got just that.







