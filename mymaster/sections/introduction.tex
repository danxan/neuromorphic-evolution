For the past 70 years, a myriad of researchers and developers has been on a quest for a human-made system that might replicate the human function and behavior \cite{haenlein_brief_2019}.
The development of autonomous systems has gotten so far it can imitate human function efficiently, but only in a few use-cases at a time.
Several scientists and philosophers have proposed theories and tools to evaluate the level of intelligence of a system.
For example, Alan Turing proposed the Turing Test, inspired by the party game The Imitation Game, to assess whether a machine is intelligent \cite{turing_computing_2009}.
Computer programs might contain autonomous functions that seem to stretch over such a broad field of capabilities
that it might fool other agents for prolonged periods. However, with time, most illusions are broken.
In the search for artificial intelligence, researchers are continuously developing new technologies and theories.

In 1943, the first mathematical neuron model was published by McCulloch and Pitts, which modeled the neuron as a logic-gate.\cite{cowan_discussion_1990}.
Through improvements to the McCulloch-Pitts neuron, by scientists as Hebb \cite{brown_legacy_2003}, we eventually got the Perceptron.
Introduced by Rosenblatt \cite{rosenblatt_perceptron_1958} and refined by Minsky et al. \cite{minsky_perceptrons_2017}, the Perceptron is a binary classifier which models synaptic plasticity and thus, enabled the first "self-\textbf{learning}" Artificial Neural Network (ANN).
ANNs, in its many forms, runs very well on modern computers based on works by Von Neumann and Alan Turing \cite{von_neumann_first_1993}, theoreticians that were highly supportive of "learning" machines. ANNs, especially with the method of Deep Learning, pioneered by LeCun et al. \cite{lecun_gradient-based_1998}, are now the most used tool for developing modern artificial intelligence technologies \cite{haenlein_brief_2019}. The use of deep learning on modern-day computer architecture has been proven very efficient for most computational tasks but also very inefficient for intricate tasks that are easily solved by biological systems.
The complexity of the functions approximated by computation is growing exponentially, and so are the energy- and material costs of the computing systems, and this is not sustainable.

As our understanding of neurobiology has progressed, more advanced models have been developed, including details of the ion flows and proteins that affect the membrane potential \cite{burkitt_review_2006}.
These models are often called Leaky Integrate and Fire Neurons, and the neural networks are often called Spiking Neural Networks (SNN). As biology has been the source of inspiration for most successful architectures of artificial intelligence \cite{minsky_perceptrons_2017}, SNNs might be the next step towards an agent of low-cost human-level intelligence.
Even though our computational power has grown exponentially for 70 years, the efficiency of our systems does not apply to extensive simulations running SNNs.
Furthermore, a more suitable technology might be required, termed Neuromorphic Systems \cite{furber_large-scale_2016}\cite{schuman_survey_2017}.

If a system can solve the same intricate tasks as a human, with ease, and also have a general behavior as a human,
it could likely pass The Turing Test, but would it then have a human level of intelligence?
Based on the plethora of theories regarding intelligence that exist today, the answer could be both yes and no \cite{haenlein_brief_2019}.
If a system was to have a human level of intelligence, one could argue that it would need to experience like a human.
Some scientists might question whether the system was conscious like a human and draw parallels to the experience of the system \cite{tononi_integrated_2016}.
The Integrated Information Theory (IIT) is one of many theories questioning consciousness and intelligence, and it provides mathematical tools
to assess information about the cognitive abilities of a system.

After unraveling the mystery of life, some scientists went on to question consciousness.
Professionals use the term consciousness with different meanings, but \textbf{some philosophers argue that being conscious requires a subjective experience, and this is how the term is to be read in this essay.}
If a system was to have a human level of intelligence, it would most likely need to have subjective experiences, and thus it would most likely need to be conscious.
IIT comes with tools to evaluate the phenomenology of a causal structure, that is,
how well a system integrates information based on experiences, and this might be a suitable tool to evaluate parts of the intelligence of a human-made system.

Most systems today that can be considered intelligent are developed on traditional computers. The problem with traditional computers is that they are highly modular, with different parts ultimately fulfilling their function in the bigger system. Modularity implies a low level of integration per definition, and it follows that all programs implemented on this arcitecture will have a low level of integration.
Using IIT to evaluate the intelligence of a computer program with autonomous functionality then seems to be useless.
However, some neuromorphic systems, built to resemble neural architecture, have more integrated architecture.
A program written for one of these systems might be considered conscious by IIT and might lead to new insights into the requirements for creating a system with a human level of intelligence.

The initial motivation behind this project was the exploration of a neuromorphic system that might lead to new applications in robotics, artifical intelligence or brain-computer interface technology.
When the cost of simulating the nervous system, which includes solving a massive amount of differential equations, can be reduced by several orders of magnitude, then a whole new world of possibilities could open:
Dynamic models of robots could be included in the control loops of the simplest of robots.
Maybe inherent characteristics in the neuromorphic system could be utilized to process complex signals, like EEG signals, with ease.
Ultimately, maybe something equivalent to human consciousness could be stored in such a system that can emulate millions of neurons at a fraction of the cost of an ordinary computer.
Nevertheless, these dreams are all hidden away in the far future.
For now, the question remains what methods are most useful when it comes to training the physical neural network that the neuromorphic system, BrainScaleS, emulates.
