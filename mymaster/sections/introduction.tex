For the past 70 years, a myriad of researchers and developers has been on a quest for a human-made system that might replicate the human function and behavior \cite{haenlein_brief_2019}.
The development of autonomous systems has gotten so far it can imitate human function efficiently, but only in a few use-cases at a time.
Several scientists and philosophers have proposed theories and tools to evaluate the level of intelligence of a system.
For example, Alan Turing proposed the Turing Test, inspired by the party game The Imitation Game, to assess whether a machine is intelligent \cite{turing_computing_2009}.
Computer programs might contain autonomous functions that seem to stretch over such a broad field of capabilities
that it might fool other agents for prolonged periods. However, with time, most illusions are broken.
In the search for artificial intelligence, researchers are continuously developing new technologies and theories.

In 1943, the first mathematical neuron model was published by McCulloch and Pitts, which modeled the neuron as a logic-gate.\cite{cowan_discussion_1990}.
Through improvements to the McCulloch-Pitts neuron, by scientists as Hebb \cite{brown_legacy_2003}, we eventually got the Perceptron.
Introduced by Rosenblatt \cite{rosenblatt_perceptron_1958} and refined by Minsky \cite{minsky_perceptrons_2017}, the Perceptron is a binary classifier which models synaptic plasticity and thus, enabled the first "self-\textbf{learning}" Artificial Neural Network (ANN).
ANNs, in its many forms, runs very well on modern computers based on works by Von Neumann and Alan Turing \cite{von_neumann_first_1993}, theoreticians that were highly supportive of "learning" machines. ANNs, especially with the method of Deep Learning, pioneered by LeCun et al. \cite{lecun_gradient-based_1998}, are now the most used tool for developing modern artificial intelligence technologies \cite{haenlein_brief_2019}. The use of deep learning on modern-day computer architecture has been proven very efficient for most computational tasks but also very inefficient for intricate tasks that are easily solved by biological systems.
When trying to solve these tasks on ordinary computers, the complexity and size of computational models are increasing so fast,
that the energy usage of computation has become a real environmental concern \cite{computation_energy_environment}.

As our understanding of neurobiology has progressed, more advanced models have been developed, including details of the ion flows and proteins that affect the membrane potential \cite{burkitt_review_2006}.
These models are often called Leaky Integrate and Fire Neurons, and the neural networks are often called Spiking Neural Networks (SNN). As biology has been the source of inspiration for most successful architectures of artificial intelligence \cite{minsky_perceptrons_2017}, SNNs might be the next step towards an agent of low-cost human-level intelligence.
Even though our computational power has grown exponentially for 70 years, the efficiency of our systems does not apply to extensive simulations running SNNs.
Furthermore, a more suitable technology might be required, termed Neuromorphic Systems \cite{furber_large-scale_2016}\cite{schuman_survey_2017}.

If a system can solve the same intricate tasks as a human, with ease, and also have a general behavior as a human,
it could likely pass The Turing Test, but would it then have a human level of intelligence?
Based on the plethora of theories regarding intelligence that exist today, the answer could be both yes and no. (ADD REFERENCE TO INTELLIGENCE DISCUSSIONS)
If a system was to have a human level of intelligence, one could argue that it would need to experience like a human.
Some scientists might question whether the system was conscious like a human and draw parallels to the experience of the system \cite{tononi_integrated_2016}.
The Integrated Information Theory (IIT) is one of many theories questioning consciousness and intelligence, and it provides mathematical tools
to assess information about the cognitive abilities of a system.

After unraveling the mystery of life, some scientists went on to question consciousness.
Professionals use the term consciousness with different meanings, but \textbf{some philosophers argue that being conscious requires a subjective experience, and this is how the term is to be read in this essay.}
If a system was to have a human level of intelligence, it would most likely need to have subjective experiences, and thus it would most likely need to be conscious.
IIT comes with tools to evaluate the phenomenology of a causal structure, that is,
how well a system integrates information based on experiences, and this might be a suitable tool to evaluate parts of the intelligence of a human-made system.

Most systems today that can be considered intelligent are developed on traditional computers. The problem with traditional computers is that they are highly modular, with different parts ultimately fulfilling their function in the bigger system. Modularity implies a low level of integration per definition, and it follows that all programs implemented on this arcitecture will have a low level of integration.
Using IIT to evaluate the intelligence of a computer program with autonomous functionality then seems to be useless.
However, some neuromorphic systems, built to resemble neural architecture, have more integrated architecture.
A program written for one of these systems might be considered conscious by IIT and might lead to new insights into the requirements for creating a system with a human level of intelligence.
