
@article{stoltz_augmented_2017,
	title = {Augmented Reality in Warehouse Operations: Opportunities and Barriers},
	volume = {50},
	issn = {24058963},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896317324291},
	doi = {10.1016/j.ifacol.2017.08.1807},
	shorttitle = {Augmented Reality in Warehouse Operations},
	pages = {12979--12984},
	number = {1},
	journaltitle = {{IFAC}-{PapersOnLine}},
	shortjournal = {{IFAC}-{PapersOnLine}},
	author = {Stoltz, Marie-Hélène and Giannikas, Vaggelis and {McFarlane}, Duncan and Strachan, James and Um, Jumyung and Srinivasan, Rengarajan},
	urldate = {2019-11-04},
	date = {2017-07},
	langid = {english},
	file = {Stoltz et al. - 2017 - Augmented Reality in Warehouse Operations Opportu.pdf:/home/danielsan/Zotero/storage/E7TNXH3S/Stoltz et al. - 2017 - Augmented Reality in Warehouse Operations Opportu.pdf:application/pdf}
}

@article{reif_pick-by-vision:_2009,
	title = {Pick-by-vision: augmented reality supported order picking},
	volume = {25},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/10.1007/s00371-009-0348-y},
	doi = {10.1007/s00371-009-0348-y},
	shorttitle = {Pick-by-vision},
	abstract = {Order picking is one of the most important process steps in logistics. Due to their ﬂexibility, human beings cannot be replaced by machines. But if workers in order picking systems are equipped with a head-mounted display, Augmented Reality can improve the information visualization. In this paper the development of such a Pick-by-Vision system is presented. It is evaluated in a user study performed in a real storage environment. Important logistic ﬁgures as well as subjective ﬁgures were measured. The results show that Pick-by-Vision can improve order picking processes on a big scale.},
	pages = {461--467},
	number = {5},
	journaltitle = {The Visual Computer},
	shortjournal = {Vis Comput},
	author = {Reif, Rupert and Günthner, Willibald A.},
	urldate = {2019-11-04},
	date = {2009-05},
	langid = {english},
	file = {Reif and Günthner - 2009 - Pick-by-vision augmented reality supported order .pdf:/home/danielsan/Zotero/storage/TAU97XGI/Reif and Günthner - 2009 - Pick-by-vision augmented reality supported order .pdf:application/pdf}
}

@article{ginters_low_2013,
	title = {Low Cost Augmented Reality and {RFID} Application for Logistics Items Visualization},
	volume = {26},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S187705091301274X},
	doi = {10.1016/j.procs.2013.12.002},
	abstract = {One important component of the gross domestic product ({GDP}) is logistics services the quality and added value of which is growing due to the application of modern information and communication technologies and electronics. {RFID} use increases the performance of logistics items identification, however some errors, which could cause substantial damage and losses, remain. The amount of potential errors could be diminished by the additional checking of items using 3D visualisation. The authors researched the use of augmented reality for item visualisation in a warehouse combining {AR} and {RFID} solutions.},
	pages = {3--13},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Ginters, Egils and Martin-Gutierrez, Jorge},
	urldate = {2019-11-04},
	date = {2013},
	langid = {english},
	file = {Ginters and Martin-Gutierrez - 2013 - Low Cost Augmented Reality and RFID Application fo.pdf:/home/danielsan/Zotero/storage/FJQYXXJF/Ginters and Martin-Gutierrez - 2013 - Low Cost Augmented Reality and RFID Application fo.pdf:application/pdf}
}

@article{moral_sequential_2006,
	title = {Sequential Monte Carlo samplers},
	volume = {68},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2006.00553.x},
	doi = {10.1111/j.1467-9868.2006.00553.x},
	abstract = {Summary. We propose a methodology to sample sequentially from a sequence of probability distributions that are defined on a common space, each distribution being known up to a normalizing constant. These probability distributions are approximated by a cloud of weighted random samples which are propagated over time by using sequential Monte Carlo methods. This methodology allows us to derive simple algorithms to make parallel Markov chain Monte Carlo algorithms interact to perform global optimization and sequential Bayesian estimation and to compute ratios of normalizing constants. We illustrate these algorithms for various integration tasks arising in the context of Bayesian inference.},
	pages = {411--436},
	number = {3},
	journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Moral, Pierre Del and Doucet, Arnaud and Jasra, Ajay},
	urldate = {2019-10-16},
	date = {2006},
	langid = {english},
	keywords = {Importance sampling, Markov chain Monte Carlo methods, Ratio of normalizing constants, Resampling, Sequential Monte Carlo methods, Simulated annealing},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/PIA46L73/Moral et al. - 2006 - Sequential Monte Carlo samplers.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/WWQA7S2P/j.1467-9868.2006.00553.html:text/html}
}

@article{doucet_efficient_2006,
	title = {Efficient Block Sampling Strategies for Sequential Monte Carlo Methods},
	volume = {15},
	issn = {1061-8600},
	url = {https://doi.org/10.1198/106186006X142744},
	doi = {10.1198/106186006X142744},
	abstract = {Sequential Monte Carlo ({SMC}) methods are a powerful set of simulation-based techniques for sampling sequentially from a sequence of complex probability distributions. These methods rely on a combination of importance sampling and resampling techniques. In a Markov chain Monte Carlo ({MCMC}) framework, block sampling strategies often perform much better than algorithms based on one-at-a-time sampling strategies if “good” proposal distributions to update blocks of variables can be designed. In an {SMC} framework, standard algorithms sequentially sample the variables one at a time whereas, like {MCMC}, the efficiency of algorithms could be improved significantly by using block sampling strategies. Unfortunately, a direct implementation of such strategies is impossible as it requires the knowledge of integrals which do not admit closed-form expressions. This article introduces a new methodology which by-passes this problem and is a natural extension of standard {SMC} methods. Applications to several sequential Bayesian inference problems demonstrate these methods.},
	pages = {693--711},
	number = {3},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Doucet, Arnaud and Briers, Mark and Sénécal, Stéphane},
	urldate = {2019-10-16},
	date = {2006-09-01},
	keywords = {Importance sampling, Block sequential Monte Carlo, Markov chain Monte Carlo, Optimal filtering, Particle filtering, State-space models},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/PEXB9KZN/Doucet et al. - 2006 - Efficient Block Sampling Strategies for Sequential.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/2JZWWDRB/106186006X142744.html:text/html}
}

@inproceedings{vahdat_mobile_2007,
	title = {Mobile robot global localization using differential evolution and particle swarm optimization},
	doi = {10.1109/CEC.2007.4424654},
	abstract = {For a mobile robot to move in a known environment and operate successfully, first it needs to robustly determine its initial position and orientation relative to the map, and then update its position while moving in the environment. Thus determining robot's position is one of the most important tasks in mobile robotics. This task consists of "global localization" and "robot's pose tracking". In this paper two recent sample-based evolutionary methods for globally localizing the position of a mobile robot are proposed. The first method is a modified version of genetic algorithm called Differential Evolution ({DE}) which is based on natural selection. The second one is Particle Swarm Optimization ({PSO}) which is based on bird flocking. {DE} evaluates initial population using the probabilistic motion and observation models and the evolution of the individuals is performed by evolutionary operators. {PSO} adjusts the velocity and location of particles towards target (robot's pose) through a problem space on the basis of information about each particle's previous best location and the best previous location of its neighbors. Our results illustrate the excellence of these two methods over standard Monte Carlo localization algorithm with regard to convergence rate, speed and computational cost.},
	eventtitle = {2007 {IEEE} Congress on Evolutionary Computation},
	pages = {1527--1534},
	booktitle = {2007 {IEEE} Congress on Evolutionary Computation},
	author = {Vahdat, Ali R. and Naser {NourAshrafoddin} and Saeed Shiry Ghidary},
	date = {2007-09},
	note = {{ISSN}: 1089-778X, 1941-0026},
	keywords = {bird flocking, Birds, Computational efficiency, Convergence, differential evolution, genetic algorithm, genetic algorithms, Genetic algorithms, global localization, Global localization, mobile robot, mobile robots, Mobile robots, Monte Carlo methods, observation models, Orbital robotics, particle swarm optimisation, particle swarm optimization, Particle swarm optimization, Performance evaluation, pose tracking, probabilistic motion, Robustness, sample-based evolutionary methods, standard Monte Carlo localization algorithm},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/J35YLHVG/4424654.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/JHCCYLS9/Vahdat et al. - 2007 - Mobile robot global localization using differentia.pdf:application/pdf}
}

@article{kanellakis_survey_2017,
	title = {Survey on Computer Vision for {UAVs}: Current Developments and Trends},
	volume = {87},
	issn = {1573-0409},
	url = {https://doi.org/10.1007/s10846-017-0483-z},
	doi = {10.1007/s10846-017-0483-z},
	shorttitle = {Survey on Computer Vision for {UAVs}},
	abstract = {During last decade the scientific research on Unmanned Aerial Vehicless ({UAVs}) increased spectacularly and led to the design of multiple types of aerial platforms. The major challenge today is the development of autonomously operating aerial agents capable of completing missions independently of human interaction. To this extent, visual sensing techniques have been integrated in the control pipeline of the {UAVs} in order to enhance their navigation and guidance skills. The aim of this article is to present a comprehensive literature review on vision based applications for {UAVs} focusing mainly on current developments and trends. These applications are sorted in different categories according to the research topics among various research groups. More specifically vision based position-attitude control, pose estimation and mapping, obstacle detection as well as target tracking are the identified components towards autonomous agents. Aerial platforms could reach greater level of autonomy by integrating all these technologies onboard. Additionally, throughout this article the concept of fusion multiple sensors is highlighted, while an overview on the challenges addressed and future trends in autonomous agent development will be also provided.},
	pages = {141--168},
	number = {1},
	journaltitle = {Journal of Intelligent \& Robotic Systems},
	shortjournal = {J Intell Robot Syst},
	author = {Kanellakis, Christoforos and Nikolakopoulos, George},
	urldate = {2019-09-04},
	date = {2017-07-01},
	langid = {english},
	keywords = {Obstacle avoidance, {SLAM}, Target tracking, {UAVs}, Visual servoing},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/WZN34CXX/Kanellakis and Nikolakopoulos - 2017 - Survey on Computer Vision for UAVs Current Develo.pdf:application/pdf}
}

@article{radovic_object_2017,
	title = {Object Recognition in Aerial Images Using Convolutional Neural Networks},
	volume = {3},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2313-433X/3/2/21},
	doi = {10.3390/jimaging3020021},
	abstract = {There are numerous applications of unmanned aerial vehicles ({UAVs}) in the management of civil infrastructure assets. A few examples include routine bridge inspections, disaster management, power line surveillance and traffic surveying. As {UAV} applications become widespread, increased levels of autonomy and independent decision-making are necessary to improve the safety, efficiency, and accuracy of the devices. This paper details the procedure and parameters used for the training of convolutional neural networks ({CNNs}) on a set of aerial images for efficient and automated object recognition. Potential application areas in the transportation field are also highlighted. The accuracy and reliability of {CNNs} depend on the network’s training and the selection of operational parameters. This paper details the {CNN} training procedure and parameter selection. The object recognition results show that by selecting a proper set of parameters, a {CNN} can detect and classify objects with a high level of accuracy (97.5\%) and computational efficiency. Furthermore, using a convolutional neural network implemented in the “{YOLO}” (“You Only Look Once”) platform, objects can be tracked, detected (“seen”), and classified (“comprehended”) from video feeds supplied by {UAVs} in real-time.},
	pages = {21},
	number = {2},
	journaltitle = {Journal of Imaging},
	author = {Radovic, Matija and Adarkwa, Offei and Wang, Qiaosong},
	urldate = {2019-09-04},
	date = {2017-06},
	langid = {english},
	keywords = {convolutional neural networks, object recognition and detection, Unmanned Aerial Vehicle ({UAV})},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/3LWMJ4UP/Radovic et al. - 2017 - Object Recognition in Aerial Images Using Convolut.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/5S6JLJAQ/htm.html:text/html}
}

@inproceedings{hudjakov_aerial_2009,
	location = {Istanbul, Turkey},
	title = {Aerial imagery terrain classification for long-range autonomous navigation},
	isbn = {978-1-4244-4209-6},
	url = {http://ieeexplore.ieee.org/document/5326104/},
	doi = {10.1109/ISOT.2009.5326104},
	abstract = {This article focuses on the problem of terrain classification from aerial imagery with the intention to increase Unmanned Ground Vehicle ({UGV}) road and off-road performance by providing means to analyze data from Unmanned Aerial Vehicle ({UAV}).},
	eventtitle = {2009 International Symposium on Optomechatronic Technologies ({ISOT} 2009)},
	pages = {88--91},
	booktitle = {2009 International Symposium on Optomechatronic Technologies},
	publisher = {{IEEE}},
	author = {Hudjakov, Robert and Tamre, Mart},
	urldate = {2019-09-04},
	date = {2009-09},
	langid = {english},
	file = {Hudjakov and Tamre - 2009 - Aerial imagery terrain classification for long-ran.pdf:/home/danielsan/Downloads/Hudjakov and Tamre - 2009 - Aerial imagery terrain classification for long-ran.pdf:application/pdf}
}

@article{prorok_reciprocal_nodate,
	title = {A Reciprocal Sampling Algorithm for Lightweight Distributed Multi-Robot Localization},
	abstract = {This work is situated in the context of collaboratively solving the localization problem for unknown initial conditions. We address this problem with a novel, fully decentralized, real-time particle ﬁlter algorithm, designed to accommodate realistic robotic assumptions including noisy sensors, and asynchronous and lossy communication. In particular, we introduce a collaborative reciprocal sampling algorithm which allows a drastic reduction in the number of particles needed to achieve localization. We elaborate an analysis of our reciprocal sampling method and support our conclusions with simulation results. Finally, we validate our approach on a team of four real robots within a controlled experimental setup.},
	pages = {7},
	author = {Prorok, Amanda and Martinoli, Alcherio},
	langid = {english},
	file = {Prorok and Martinoli - A Reciprocal Sampling Algorithm for Lightweight Di.pdf:/home/danielsan/Downloads/Prorok and Martinoli - A Reciprocal Sampling Algorithm for Lightweight Di.pdf:application/pdf}
}

@incollection{ruiz-del-solar_cooperative_2011,
	location = {Berlin, Heidelberg},
	title = {Cooperative Localization Based on Visually Shared Objects},
	volume = {6556},
	isbn = {978-3-642-20216-2 978-3-642-20217-9},
	url = {http://link.springer.com/10.1007/978-3-642-20217-9_30},
	abstract = {In this paper we describe a cooperative localization algorithm based on a modiﬁcation of the Monte Carlo Localization algorithm where, when a robot detects it is lost, particles are spread not uniformly in the state space, but rather according to the information on the location of an object whose distance and bearing is measured by the lost robot. The object location is provided by other robots of the same team using explicit (wireless) communication. Results of application of the method to a team of real robots are presented.},
	pages = {350--361},
	booktitle = {{RoboCup} 2010: Robot Soccer World Cup {XIV}},
	publisher = {Springer Berlin Heidelberg},
	author = {Lima, Pedro U. and Santos, Pedro and Oliveira, Ricardo and Ahmad, Aamir and Santos, João},
	editor = {Ruiz-del-Solar, Javier and Chown, Eric and Plöger, Paul G.},
	urldate = {2019-09-04},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-20217-9_30},
	file = {Lima et al. - 2011 - Cooperative Localization Based on Visually Shared .pdf:/home/danielsan/Downloads/Lima et al. - 2011 - Cooperative Localization Based on Visually Shared .pdf:application/pdf}
}

@inproceedings{wang_dynamic_2010,
	location = {Tianjin, China},
	title = {A dynamic size {MCL} algorithm for mobile robot localization},
	isbn = {978-1-4244-9319-7},
	url = {http://ieeexplore.ieee.org/document/5723426/},
	doi = {10.1109/ROBIO.2010.5723426},
	abstract = {Mobile robot localization is a very important problem in robotics as most robot’s tasks need the positional information. Monte Carlo Localization({MCL}) is one of the most popular and efﬁcient localization algorithms for mobile robot localization. {MCL} algorithm represents a robot’s pose by a set of weighted particles. In order to further improve the performance of {MCL}, many extensions have been proposed. In this paper, we proposed an algorithm called dynamic size {MCL}, an extension of {MCL}. We incorporate the clustering approach into traditional {MCL}. With the help of clustering information, our algorithm could reduce the number of particles during the process of localization, which lower the computational cost. Experimental results demonstrate the effectiveness of the proposed method.},
	eventtitle = {2010 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
	pages = {785--790},
	booktitle = {2010 {IEEE} International Conference on Robotics and Biomimetics},
	publisher = {{IEEE}},
	author = {Wang, Yuefeng and Wu, Dan and Wu, Libing},
	urldate = {2019-09-04},
	date = {2010-12},
	langid = {english},
	file = {Wang et al. - 2010 - A dynamic size MCL algorithm for mobile robot loca.pdf:/home/danielsan/Downloads/Wang et al. - 2010 - A dynamic size MCL algorithm for mobile robot loca.pdf:application/pdf}
}

@inproceedings{min_active_2009,
	location = {Zhuhai/Macau, China},
	title = {Active particle in {MCL}: An evolutionary view},
	isbn = {978-1-4244-3607-1},
	url = {http://ieeexplore.ieee.org/document/5205079/},
	doi = {10.1109/ICINFA.2009.5205079},
	shorttitle = {Active particle in {MCL}},
	abstract = {Mobile robot localization is the task of determining a robot's pose in a known environment, which is one of the most important problems in mobile robotics. The state-of-the-art Monte Carlo Localization ({MCL}) algorithm requires a large amount of particles and thus converges slowly. Also, {MCL} performs poorly in low noise sensor input.},
	eventtitle = {2009 International Conference on Information and Automation ({ICIA})},
	pages = {1087--1092},
	booktitle = {2009 International Conference on Information and Automation},
	publisher = {{IEEE}},
	author = {Min, Hua-Qing and Chen, Huan and Luo, Rong-Hua},
	urldate = {2019-09-04},
	date = {2009-06},
	langid = {english},
	file = {Min et al. - 2009 - Active particle in MCL An evolutionary view.pdf:/home/danielsan/Downloads/Min et al. - 2009 - Active particle in MCL An evolutionary view.pdf:application/pdf}
}

@article{bruederle_establishing_2009,
	title = {Establishing a Novel Modeling Tool: A Python-based Interface for a Neuromorphic Hardware System},
	volume = {3},
	issn = {16625196},
	url = {http://journal.frontiersin.org/article/10.3389/neuro.11.017.2009/abstract},
	doi = {10.3389/neuro.11.017.2009},
	shorttitle = {Establishing a Novel Modeling Tool},
	abstract = {Neuromorphic hardware systems provide new possibilities for the neuroscience modeling community. Due to the intrinsic parallelism of the micro-electronic emulation of neural computation, such models are highly scalable without a loss of speed. However, the communities of software simulator users and neuromorphic engineering in neuroscience are rather disjoint. We present a software concept that provides the possibility to establish such hardware devices as valuable modeling tools. It is based on the integration of the hardware interface into a simulator-independent language which allows for uniﬁed experiment descriptions that can be run on various simulation platforms without modiﬁcation, implying experiment portability and a huge simpliﬁcation of the quantitative comparison of hardware and simulator results. We introduce an accelerated neuromorphic hardware device and describe the implementation of the proposed concept for this system. An example setup and results acquired by utilizing both the hardware system and a software simulator are demonstrated.},
	journaltitle = {Frontiers in Neuroinformatics},
	shortjournal = {Front. Neuroinform.},
	author = {Bruederle, Daniel},
	urldate = {2019-08-29},
	date = {2009},
	langid = {english},
	file = {Bruederle - 2009 - Establishing a Novel Modeling Tool A Python-based.pdf:/home/danielsan/Downloads/Bruederle - 2009 - Establishing a Novel Modeling Tool A Python-based.pdf:application/pdf}
}

@inproceedings{schemmel_wafer-scale_2010,
	location = {Paris, France},
	title = {A wafer-scale neuromorphic hardware system for large-scale neural modeling},
	isbn = {978-1-4244-5308-5},
	url = {http://ieeexplore.ieee.org/document/5536970/},
	doi = {10.1109/ISCAS.2010.5536970},
	abstract = {Modeling neural tissue is an important tool to investigate biological neural networks. Until recently, most of this modeling has been done using numerical methods. In the European research project ”{FACETS}” this computational approach is complemented by different kinds of neuromorphic systems. A special emphasis lies in the usability of these systems for neuroscience. To accomplish this goal an integrated software/hardware framework has been developed which is centered around a uniﬁed neural system description language, called {PyNN}, that allows the scientist to describe a model and execute it in a transparent fashion on either a neuromorphic hardware system or a numerical simulator. A very large analog neuromorphic hardware system developed within {FACETS} is able to use complex neural models as well as realistic network topologies, i.e. it can realize more than 10000 synapses per neuron, to allow the direct execution of models which previously could have been simulated numerically only.},
	eventtitle = {2010 {IEEE} International Symposium on Circuits and Systems - {ISCAS} 2010},
	pages = {1947--1950},
	booktitle = {Proceedings of 2010 {IEEE} International Symposium on Circuits and Systems},
	publisher = {{IEEE}},
	author = {Schemmel, Johannes and Briiderle, Daniel and Griibl, Andreas and Hock, Matthias and Meier, Karlheinz and Millner, Sebastian},
	urldate = {2019-08-29},
	date = {2010-05},
	langid = {english},
	file = {Schemmel et al. - 2010 - A wafer-scale neuromorphic hardware system for lar.pdf:/home/danielsan/Downloads/Schemmel et al. - 2010 - A wafer-scale neuromorphic hardware system for lar.pdf:application/pdf}
}

@article{aamir_accelerated_2018,
	title = {An Accelerated {LIF} Neuronal Network Array for a Large-Scale Mixed-Signal Neuromorphic Architecture},
	volume = {65},
	issn = {1549-8328, 1558-0806},
	url = {https://ieeexplore.ieee.org/document/8398542/},
	doi = {10.1109/TCSI.2018.2840718},
	abstract = {We present an array of leaky integrate-andﬁre ({LIF}) neuron circuits designed for the second-generation {BrainScaleS} mixed-signal 65-nm {CMOS} neuromorphic hardware. The neuronal array is embedded in the analog network core of a scaled-down prototype high input count analog neural network with digital learning system chip. Designed as continuoustime circuits, the neurons are highly tunable and reconﬁgurable elements with accelerated dynamics. Each neuron integrates input current from a multitude of incoming synapses and evokes a digital spike event output. The circuit offers a wide tuning range for synaptic and membrane time constants, as well as for refractory periods to cover a number of computational models. We elucidate our design methodology, underlying circuit design, calibration, and measurement results from individual sub-circuits across multiple dies. The circuit dynamics matches with the behavior of the {LIF} mathematical model. We further demonstrate a winner-take-all network on the prototype chip as a typical element of cortical processing.},
	pages = {4299--4312},
	number = {12},
	journaltitle = {{IEEE} Transactions on Circuits and Systems I: Regular Papers},
	shortjournal = {{IEEE} Trans. Circuits Syst. I},
	author = {Aamir, Syed Ahmed and Stradmann, Yannik and Muller, Paul and Pehle, Christian and Hartel, Andreas and Grubl, Andreas and Schemmel, Johannes and Meier, Karlheinz},
	urldate = {2019-08-29},
	date = {2018-12},
	langid = {english},
	file = {Aamir et al. - 2018 - An Accelerated LIF Neuronal Network Array for a La.pdf:/home/danielsan/Downloads/Aamir et al. - 2018 - An Accelerated LIF Neuronal Network Array for a La.pdf:application/pdf}
}

@article{mantelli_novel_2019,
	title = {A novel measurement model based on {abBRIEF} for global localization of a {UAV} over satellite images},
	volume = {112},
	issn = {09218890},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092188901830438X},
	doi = {10.1016/j.robot.2018.12.006},
	abstract = {This paper presents a method for global localization and tracking of an Unmanned Aerial Vehicle ({UAV}) over satellite images. We propose a new measurement model based on a novel version of {BRIEF} descriptor and apply it in a Monte Carlo Localization system that estimates the {UAV} pose in 4 degrees of freedom. The model is used to compare images obtained from the {UAV} downward looking camera against patches of satellite images such as the ones available on {GoogleTMEarth}. The proposed method was validated using real flights sequences and has yield good results with different maps of the same region spawning many years and covering large areas.},
	pages = {304--319},
	journaltitle = {Robotics and Autonomous Systems},
	shortjournal = {Robotics and Autonomous Systems},
	author = {Mantelli, Mathias and Pittol, Diego and Neuland, Renata and Ribacki, Arthur and Maffei, Renan and Jorge, Vitor and Prestes, Edson and Kolberg, Mariana},
	urldate = {2019-08-28},
	date = {2019-02},
	langid = {english},
	file = {Mantelli et al. - 2019 - A novel measurement model based on abBRIEF for glo.pdf:/home/danielsan/Downloads/Mantelli et al. - 2019 - A novel measurement model based on abBRIEF for glo.pdf:application/pdf}
}

@incollection{menegatti_localization_2016,
	location = {Cham},
	title = {Localization of Unmanned Aerial Vehicles Using Terrain Classification from Aerial Images},
	volume = {302},
	isbn = {978-3-319-08337-7 978-3-319-08338-4},
	url = {http://link.springer.com/10.1007/978-3-319-08338-4_60},
	abstract = {In this paper we investigate the beneﬁt of terrain classiﬁcation for selflocalization of a ﬂying robot. The key idea is to use aerial images, which are already available from online databases such as {GoogleMaps}™, as reference map and to match images taken with a downward looking camera with this map. Using different terrain classes as features, we can make sure that our method is invariant to lighting/weather changes as well as seasonal variations or minor changes in the environment. A particle ﬁlter is used to register the query image with parts of the map. The proposed method has shown to work on image data from both simulated and real ﬂights.},
	pages = {831--842},
	booktitle = {Intelligent Autonomous Systems 13},
	publisher = {Springer International Publishing},
	author = {Masselli, Andreas and Hanten, Richard and Zell, Andreas},
	editor = {Menegatti, Emanuele and Michael, Nathan and Berns, Karsten and Yamaguchi, Hiroaki},
	urldate = {2019-08-28},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-08338-4_60},
	file = {Masselli et al. - 2016 - Localization of Unmanned Aerial Vehicles Using Ter.pdf:/home/danielsan/Downloads/Masselli et al. - 2016 - Localization of Unmanned Aerial Vehicles Using Ter.pdf:application/pdf}
}

@inproceedings{dellaert_monte_1999,
	location = {Detroit, {MI}, {USA}},
	title = {Monte Carlo localization for mobile robots},
	volume = {2},
	isbn = {978-0-7803-5180-6},
	url = {http://ieeexplore.ieee.org/document/772544/},
	doi = {10.1109/ROBOT.1999.772544},
	abstract = {To navigate reliablyin indoor environments,a mobile robot must know where it is. Thus, reliableposition estimation is a key problem in mobile robotics. We believe that probabilistic approaches are among the most promising candidates to providing a comprehensive and real-time solution to the robot localization problem. Howevel; current methods still face considerable hurdles. In particular; the problems encountered are closely related to the type of representation used to represent probability densities over the robot’s state space. Recent work on Bayesian jiltering with particle-based density representations opens up a new approachfor mobile robot localization, based on these principles. In this paper we introduce the Monte Carlo Localization method, where we represent the probability density involved by maintaining a set of samples that are randomly drawnfrom it. By using a sampling-based representation we obtain a localization method that can represent arbitrary distributions. We show experimentally that the resulting method is able to efficiently localize a mobile robot without knowledge of its starting location. It is faster; more accurate and less memory-intensive than earlier grid-based methods.},
	eventtitle = {International Conference on Robotics and Automation},
	pages = {1322--1328},
	booktitle = {Proceedings 1999 {IEEE} International Conference on Robotics and Automation (Cat. No.99CH36288C)},
	publisher = {{IEEE}},
	author = {Dellaert, F. and Fox, D. and Burgard, W. and Thrun, S.},
	urldate = {2019-08-28},
	date = {1999},
	langid = {english},
	file = {Dellaert et al. - 1999 - Monte Carlo localization for mobile robots.pdf:/home/danielsan/Downloads/Dellaert et al. - 1999 - Monte Carlo localization for mobile robots.pdf:application/pdf}
}

@article{maass_noise_2014,
	title = {Noise as a Resource for Computation and Learning in Networks of Spiking Neurons},
	volume = {102},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2014.2310593},
	abstract = {We are used to viewing noise as a nuisance in computing systems. This is a pity, since noise will be abundantly available in energy-efficient future nanoscale devices and circuits. I propose here to learn from the way the brain deals with noise, and apparently even benefits from it. Recent theoretical results have provided insight into how this can be achieved: how noise enables networks of spiking neurons to carry out probabilistic inference through sampling and also enables creative problem solving. In addition, noise supports the self-organization of networks of spiking neurons, and learning from rewards. I will sketch here the main ideas and some consequences of these results. I will also describe why these results are paving the way for a qualitative jump in the computational capability and learning performance of neuromorphic networks of spiking neurons with noise, and for other future computing systems that are able to treat noise as a resource.},
	pages = {860--880},
	number = {5},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Maass, W.},
	date = {2014-05},
	keywords = {brain, computational capability, Computational power, Computer architecture, computing systems, creative problem solving, energy-efficient device, learning performance, Markov processes, medical computing, nanoscale circuits, nanoscale devices, neural nets, neural networks, Neural networks, neuromorphic hardware, neuromorphic networks, Neurons, neurophysiology, Neuroscience, noise, Noise measurement, nuisance, probabilistic inference, Probabilistic logic, probability, qualitative jump, resource, sampling, self-organization, Self-organizing networks, spiking neuron networks, spiking neurons, stochastic computing, Stochastic processes},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/N8SLKGGE/6797856.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/XKGAVW5G/Maass - 2014 - Noise as a Resource for Computation and Learning i.pdf:application/pdf}
}

@inproceedings{zoschke_full_2017,
	title = {Full wafer redistribution and wafer embedding as key technologies for a multi-scale neuromorphic hardware cluster},
	doi = {10.1109/EPTC.2017.8277579},
	abstract = {Together with the Kirchhoff-Institute for Physics the Fraunhofer {IZM} has developed a full wafer redistribution and embedding technology as base for a large-scale neuromorphic hardware system. The paper will give an overview of the neuromorphic computing platform at the Kirchhoff-Institute for Physics and the associated hardware requirements which drove the described technological developments. In the first phase of the project standard redistribution technologies from wafer level packaging were adapted to enable a high density reticle-to-reticle routing on 200 mm {CMOS} wafers. Neighboring reticles were interconnected across the scribe lines with an 8 μm pitch routing based on semi-additive copper metallization which was photo defined by full field mask aligning equipment. Passivation by photo sensitive benzocyclobutene ({BCB}) was used to enable a second intra-reticle routing layer. Final {IO} pads of nickel with flash gold were generated on top of each reticle. For final electrical connection the wafers were placed into mechanical fixtures and the {IOs} of all reticles were touched by elastomeric connectors. With that concept neuromorphic systems based on full wafers could be assembled and tested. The fabricated high density inter-reticle routing revealed a very high yield of larger than 99.9 \%. In order to allow an upscaling of the system size to a large number of wafers with feasible effort a full wafer embedding concept for printed circuit boards was developed and proven in the second phase of the project. The wafers were thinned to 250 μm and laminated with additional prepreg layers and copper foils into a core material. A 200 mm circular cut was done into the core material and the inner prepreg layers to create the required clearance for the wafer. After lamination of the {PCB} panel the reticle {IOs} of the embedded wafer were accessed by micro via drilling, copper electroplating, lithography and subtractive etching of the {PCB} wiring structure. The created wiring with 50 μm line width enabled an access of the reticle {IOs} on the embedded wafer as well as a board level routing. The panels with the embedded wafers were subsequently stressed with up to 1000 thermal cycles between 0 °C and 100 °C and have shown no severe failure formation over the cycle time.},
	eventtitle = {2017 {IEEE} 19th Electronics Packaging Technology Conference ({EPTC})},
	pages = {1--8},
	booktitle = {2017 {IEEE} 19th Electronics Packaging Technology Conference ({EPTC})},
	author = {Zoschke, K. and Güttler, M. and Böttcher, L. and Grübl, A. and Husmann, D. and Schemmel, J. and Meier, K. and Ehrmann, O.},
	date = {2017-12},
	keywords = {Neurons, associated hardware requirements, {CMOS} digital integrated circuits, {CMOS} wafers, concept neuromorphic systems, copper, Copper, described technological developments, electric connectors, electroplating, embedding technology, etching, fabricated high density inter-reticle routing, Field programmable gate arrays, Fraunhofer {IZM}, gold, integrated circuit interconnections, integrated circuit reliability, interconnections, intra-reticle routing layer, Kirchhoff-Institute for Physics, large-scale neuromorphic hardware system, lithography, masks, multiscale neuromorphic hardware cluster, neighboring reticles, network routing, neural chips, neuromorphic computing platform, Polymers, printed circuit manufacture, printed circuits, project standard redistribution technologies, reticle {IO}, reticle-to-reticle routing, Routing, size 200.0 mm, size 250.0 mum, size 50.0 mum, size 8.0 mum, sputter etching, Standards, temperature 0.0 {degC} to 100.0 {degC}, wafer embedding, wafer level packaging, wafer redistribution, Wiring},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/G4CSE3N5/8277579.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/GBWJ8YUM/Zoschke et al. - 2017 - Full wafer redistribution and wafer embedding as k.pdf:application/pdf}
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	rights = {2015 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	abstract = {The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
	pages = {529--533},
	number = {7540},
	journaltitle = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	urldate = {2019-08-21},
	date = {2015-02},
	langid = {english},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/HWRA5KJY/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/NRJ4B77E/nature14236.html:text/html}
}

@article{friedmann_demonstrating_2017,
	title = {Demonstrating Hybrid Learning in a Flexible Neuromorphic Hardware System},
	volume = {11},
	issn = {1932-4545},
	doi = {10.1109/TBCAS.2016.2579164},
	abstract = {We present results from a new approach to learning and plasticity in neuromorphic hardware systems: to enable flexibility in implementable learning mechanisms while keeping high efficiency associated with neuromorphic implementations, we combine a general-purpose processor with full-custom analog elements. This processor is operating in parallel with a fully parallel neuromorphic system consisting of an array of synapses connected to analog, continuous time neuron circuits. Novel analog correlation sensor circuits process spike events for each synapse in parallel and in real-time. The processor uses this pre-processing to compute new weights possibly using additional information following its program. Therefore, to a certain extent, learning rules can be defined in software giving a large degree of flexibility. Synapses realize correlation detection geared towards Spike-Timing Dependent Plasticity ({STDP}) as central computational primitive in the analog domain. Operating at a speed-up factor of 1000 compared to biological time-scale, we measure time-constants from tens to hundreds of micro-seconds. We analyze variability across multiple chips and demonstrate learning using a multiplicative {STDP} rule. We conclude that the presented approach will enable flexible and efficient learning as a platform for neuroscientific research and technological applications.},
	pages = {128--142},
	number = {1},
	journaltitle = {{IEEE} Transactions on Biomedical Circuits and Systems},
	author = {Friedmann, S. and Schemmel, J. and Grübl, A. and Hartel, A. and Hock, M. and Meier, K.},
	date = {2017-02},
	keywords = {neuromorphic hardware, Neurons, neurophysiology, analog continuous time neuron circuits, analog correlation sensor circuits, bioelectric phenomena, Biological system modeling, Correlation, Digital signal processing, flexible neuromorphic hardware system, full-custom analog elements, Hardware, hybrid learning, learning, learning (artificial intelligence), Machine Learning, Mathematical model, medical signal processing, Models, Neurological, Neural Networks (Computer), neuromorphic implementations, Neuromorphics, Neuronal Plasticity, neuroscientific research, spike events, spike-time dependent plasticity, spike-timing dependent plasticity, {STDP}, synapse circuit, synapses, Synapses},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/I9K243BX/7563782.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/SWMETM8I/Friedmann et al. - 2017 - Demonstrating Hybrid Learning in a Flexible Neurom.pdf:application/pdf}
}

@online{hodgkin_quantitative_1952,
	title = {A quantitative description of membrane current and its application to conduction and excitation in nerve},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1952.sp004764},
	titleaddon = {The Journal of Physiology},
	author = {Hodgkin, A. L. and Huxley, A. F.},
	urldate = {2019-08-21},
	date = {1952-08-28},
	langid = {english},
	doi = {10.1113/jphysiol.1952.sp004764},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/I5QP6N5X/Hodgkin and Huxley - 1952 - A quantitative description of membrane current and.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/X78KL5GV/jphysiol.1952.html:text/html}
}

@article{scholze_32_2012,
	title = {A 32 {GBit}/s communication {SoC} for a waferscale neuromorphic system},
	volume = {45},
	issn = {01679260},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167926011000538},
	doi = {10.1016/j.vlsi.2011.05.003},
	abstract = {State-of-the-art large-scale neuromorphic systems require a sophisticated, high-bandwidth communication infrastructure for the exchange of spike events between units of the neural network. These communication infrastructures are usually built around custom-designed {FPGA} systems. However, the overall bandwidth requirements and the integration density of very large neuromorphic systems necessitate a signiﬁcantly more targeted approach, i.e. the development of dedicated integrated circuits. We present a {VLSI} realization of a neuromorphic communication system-on-chip ({SoC}) with a cumulative throughput of 32 {GBit}/s in 0:18 mm {CMOS}, employing state-of-the-art circuit blocks. Several of these circuits exhibit improved performance compared to current literature, e.g. a priority queue with a speed of 31 Mkeys/s at 1.3 {mW}, or a 1 {GHz} {PLL} at 5 {mW}. The {SoC} contains additional neuromorphic functionality, such as conﬁgurable event delays and event ordering. The complete conﬁguration of the neuromorphic system is also handled by the spike communication channels, in contrast to the separate channels required in the majority of current systems. At 865 Mevent/s, the {SoC} delivers at least a factor of eight more bandwidth than other current neuromorphic communication infrastructures.},
	pages = {61--75},
	number = {1},
	journaltitle = {Integration},
	shortjournal = {Integration},
	author = {Scholze, Stefan and Eisenreich, Holger and Höppner, Sebastian and Ellguth, Georg and Henker, Stephan and Ander, Mario and Hänzsche, Stefan and Partzsch, Johannes and Mayr, Christian and Schüffny, René},
	urldate = {2019-08-21},
	date = {2012-01},
	langid = {english},
	file = {Scholze et al. - 2012 - A 32 GBits communication SoC for a waferscale neu.pdf:/home/danielsan/Downloads/Scholze et al. - 2012 - A 32 GBits communication SoC for a waferscale neu.pdf:application/pdf}
}

@article{sun_organic_2018,
	title = {Organic synaptic devices for neuromorphic systems},
	volume = {51},
	issn = {0022-3727, 1361-6463},
	url = {http://stacks.iop.org/0022-3727/51/i=31/a=314004?key=crossref.b4e835c96a6ecbe4766f89b7016c8b56},
	doi = {10.1088/1361-6463/aacd99},
	abstract = {The development of synaptic devices with biologically-inspired information processing functions and low power consumption is critically important for the hardware implementation of highly anticipated brain-like computing systems. Organic materials are regarded as the most promising candidates for synaptic devices and bio-electronics due to several advantages such as low cost, easy processability, mechanical flexibility and ductility. In this review, a description of the current advances in organic synaptic devices, including two-terminal memristors and three-terminal transistors, is provided. Organic two-terminal memristors with the characteristics of non-volatility and reasonable on/off switching ratio are reported to be popular synaptic devices. On the other hand, organic memristive and electrochemical electric-double-layer transistors can accurately select working devices by applying a gate spike to the corresponding gate electrode. Therefore, these three-terminal organic devices provide an alternative approach to the development of neuromorphic systems. Lastly, the novel applications of organic synaptic devices are discussed, and some current challenges are presented.},
	pages = {314004},
	number = {31},
	journaltitle = {Journal of Physics D: Applied Physics},
	shortjournal = {J. Phys. D: Appl. Phys.},
	author = {Sun, Jia and Fu, Ying and Wan, Qing},
	urldate = {2019-08-21},
	date = {2018-08-08},
	langid = {english},
	file = {Sun et al. - 2018 - Organic synaptic devices for neuromorphic systems.pdf:/home/danielsan/Downloads/Sun et al. - 2018 - Organic synaptic devices for neuromorphic systems.pdf:application/pdf}
}

@article{indiveri_integration_2013,
	title = {Integration of nanoscale memristor synapses in neuromorphic computing architectures},
	volume = {24},
	issn = {0957-4484, 1361-6528},
	url = {http://stacks.iop.org/0957-4484/24/i=38/a=384010?key=crossref.021ddc6521275e62cd80c69b1b841f4f},
	doi = {10.1088/0957-4484/24/38/384010},
	abstract = {Conventional neuro-computing architectures and artiﬁcial neural networks have often been developed with no or loose connections to neuroscience. As a consequence, they have largely ignored key features of biological neural processing systems, such as their extremely low-power consumption features or their ability to carry out robust and efﬁcient computation using massively parallel arrays of limited precision, highly variable, and unreliable components. Recent developments in nano-technologies are making available extremely compact and low power, but also variable and unreliable solid-state devices that can potentially extend the offerings of availing {CMOS} technologies. In particular, memristors are regarded as a promising solution for modeling key features of biological synapses due to their nanoscale dimensions, their capacity to store multiple bits of information per element and the low energy required to write distinct states. In this paper, we ﬁrst review the neuro- and neuromorphic computing approaches that can best exploit the properties of memristor and scale devices, and then propose a novel hybrid memristor-{CMOS} neuromorphic circuit which represents a radical departure from conventional neuro-computing approaches, as it uses memristors to directly emulate the biophysics and temporal dynamics of real synapses. We point out the differences between the use of memristors in conventional neuro-computing architectures and the hybrid memristor-{CMOS} circuit proposed, and argue how this circuit represents an ideal building block for implementing brain-inspired probabilistic computing paradigms that are robust to variability and fault tolerant by design.},
	pages = {384010},
	number = {38},
	journaltitle = {Nanotechnology},
	shortjournal = {Nanotechnology},
	author = {Indiveri, Giacomo and Linares-Barranco, Bernabé and Legenstein, Robert and Deligeorgis, George and Prodromakis, Themistoklis},
	urldate = {2019-08-21},
	date = {2013-09-27},
	langid = {english},
	file = {Indiveri et al. - 2013 - Integration of nanoscale memristor synapses in neu.pdf:/home/danielsan/Downloads/Indiveri et al. - 2013 - Integration of nanoscale memristor synapses in neu.pdf:application/pdf}
}

@article{broccard_neuromorphic_2017,
	title = {Neuromorphic neural interfaces: from neurophysiological inspiration to biohybrid coupling with nervous systems},
	volume = {14},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/14/i=4/a=041002?key=crossref.d8833bdd885d2d1769d7475fb038dcc1},
	doi = {10.1088/1741-2552/aa67a9},
	shorttitle = {Neuromorphic neural interfaces},
	abstract = {Objective. Computation in nervous systems operates with different computational primitives, and on different hardware, than traditional digital computation and is thus subjected to different constraints from its digital counterpart regarding the use of physical resources such as time, space and energy. In an effort to better understand neural computation on a physical medium with similar spatiotemporal and energetic constraints, the field of neuromorphic engineering aims to design and implement electronic systems that emulate in very large-scale integration ({VLSI}) hardware the organization and functions of neural systems at multiple levels of biological organization, from individual neurons up to large circuits and networks. Mixed analog/digital neuromorphic {VLSI} systems are compact, consume little power and operate in real time independently of the size and complexity of the model. Approach. This article highlights the current efforts to interface neuromorphic systems with neural systems at multiple levels of biological organization, from the synaptic to the system level, and discusses the prospects for future biohybrid systems with neuromorphic circuits of greater complexity. Main results. Single silicon neurons have been interfaced successfully with invertebrate and vertebrate neural networks. This approach allowed the investigation of neural properties that are inaccessible with traditional techniques while providing a realistic biological context not achievable with traditional numerical modeling methods. At the network level, populations of neurons are envisioned to communicate bidirectionally with neuromorphic processors of hundreds or thousands of silicon neurons. Recent work on brain–machine interfaces suggests that this is feasible with current neuromorphic technology. Significance. Biohybrid interfaces between biological neurons and {VLSI} neuromorphic systems of varying complexity have started to emerge in the literature. Primarily intended as a computational tool for investigating fundamental questions related to neural dynamics, the sophistication of current neuromorphic systems now allows direct interfaces with large neuronal networks and circuits, resulting in potentially interesting clinical applications for neuroengineering systems, neuroprosthetics and neurorehabilitation.},
	pages = {041002},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Broccard, Frédéric D and Joshi, Siddharth and Wang, Jun and Cauwenberghs, Gert},
	urldate = {2019-08-21},
	date = {2017-08-01},
	langid = {english},
	file = {Broccard et al. - 2017 - Neuromorphic neural interfaces from neurophysiolo.pdf:/home/danielsan/Downloads/Broccard et al. - 2017 - Neuromorphic neural interfaces from neurophysiolo.pdf:application/pdf}
}

@article{furber_large-scale_2016,
	title = {Large-scale neuromorphic computing systems},
	volume = {13},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/13/i=5/a=051001?key=crossref.c170009b6af4be582bc1fbfbf3ccad04},
	doi = {10.1088/1741-2560/13/5/051001},
	abstract = {Neuromorphic computing covers a diverse range of approaches to information processing all of which demonstrate some degree of neurobiological inspiration that differentiates them from mainstream conventional computing systems. The philosophy behind neuromorphic computing has its origins in the seminal work carried out by Carver Mead at Caltech in the late 1980s. This early work inﬂuenced others to carry developments forward, and advances in {VLSI} technology supported steady growth in the scale and capability of neuromorphic devices. Recently, a number of large-scale neuromorphic projects have emerged, taking the approach to unprecedented scales and capabilities. These large-scale projects are associated with major new funding initiatives for brain-related research, creating a sense that the time and circumstances are right for progress in our understanding of information processing in the brain. In this review we present a brief history of neuromorphic engineering then focus on some of the principal current large-scale projects, their main features, how their approaches are complementary and distinct, their advantages and drawbacks, and highlight the sorts of capabilities that each can deliver to neural modellers.},
	pages = {051001},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Furber, Steve},
	urldate = {2019-08-21},
	date = {2016-10-01},
	langid = {english},
	file = {Furber - 2016 - Large-scale neuromorphic computing systems.pdf:/home/danielsan/Downloads/Furber - 2016 - Large-scale neuromorphic computing systems.pdf:application/pdf}
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2019-08-21},
	date = {2015-05},
	langid = {english},
	file = {LeCun et al. - 2015 - Deep learning.pdf:/home/danielsan/Downloads/LeCun et al. - 2015 - Deep learning.pdf:application/pdf}
}

@article{albantakis_evolution_2014,
	title = {Evolution of Integrated Causal Structures in Animats Exposed to Environments of Increasing Complexity},
	volume = {10},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003966},
	doi = {10.1371/journal.pcbi.1003966},
	abstract = {Natural selection favors the evolution of brains that can capture fitness-relevant features of the environment’s causal structure. We investigated the evolution of small, adaptive logic-gate networks (‘‘animats’’) in task environments where falling blocks of different sizes have to be caught or avoided in a ‘Tetris-like’ game. Solving these tasks requires the integration of sensor inputs and memory. Evolved networks were evaluated using measures of information integration, including the number of evolved concepts and the total amount of integrated conceptual information. The results show that, over the course of the animats’ adaptation, i) the number of concepts grows; ii) integrated conceptual information increases; iii) this increase depends on the complexity of the environment, especially on the requirement for sequential memory. These results suggest that the need to capture the causal structure of a rich environment, given limited sensors and internal mechanisms, is an important driving force for organisms to develop highly integrated networks (‘‘brains’’) with many concepts, leading to an increase in their internal complexity.},
	pages = {e1003966},
	number = {12},
	journaltitle = {{PLoS} Computational Biology},
	author = {Albantakis, Larissa and Hintze, Arend and Koch, Christof and Adami, Christoph and Tononi, Giulio},
	editor = {Polani, Daniel},
	urldate = {2019-04-04},
	date = {2014-12-18},
	langid = {english},
	file = {Albantakis et al. - 2014 - Evolution of Integrated Causal Structures in Anima.PDF:/home/danielsan/Zotero/storage/LR3TAQUN/Albantakis et al. - 2014 - Evolution of Integrated Causal Structures in Anima.PDF:application/pdf}
}

@inproceedings{schmitt_neuromorphic_2017,
	location = {Anchorage, {AK}},
	title = {Neuromorphic hardware in the loop: Training a deep spiking network on the {BrainScaleS} wafer-scale system},
	isbn = {978-1-5090-6182-2},
	url = {http://ieeexplore.ieee.org/document/7966125/},
	doi = {10.1109/IJCNN.2017.7966125},
	shorttitle = {Neuromorphic hardware in the loop},
	abstract = {Emulating spiking neural networks on analog neuromorphic hardware offers several advantages over simulating them on conventional computers, particularly in terms of speed and energy consumption. However, this usually comes at the cost of reduced control over the dynamics of the emulated networks. In this paper, we demonstrate how iterative training of a hardware-emulated network can compensate for anomalies induced by the analog substrate. We ﬁrst convert a deep neural network trained in software to a spiking network on the {BrainScaleS} wafer-scale neuromorphic system, thereby enabling an acceleration factor of 10 000 compared to the biological time domain. This mapping is followed by the in-the-loop training, where in each training step, the network activity is ﬁrst recorded in hardware and then used to compute the parameter updates in software via backpropagation. An essential ﬁnding is that the parameter updates do not have to be precise, but only need to approximately follow the correct gradient, which simpliﬁes the computation of updates. Using this approach, after only several tens of iterations, the spiking network shows an accuracy close to the ideal software-emulated prototype. The presented techniques show that deep spiking networks emulated on analog neuromorphic devices can attain good computational performance despite the inherent variations of the analog substrate.},
	eventtitle = {2017 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {2227--2234},
	booktitle = {2017 International Joint Conference on Neural Networks ({IJCNN})},
	publisher = {{IEEE}},
	author = {Schmitt, Sebastian and Klahn, Johann and Bellec, Guillaume and Grubl, Andreas and Guttler, Maurice and Hartel, Andreas and Hartmann, Stephan and Husmann, Dan and Husmann, Kai and Jeltsch, Sebastian and Karasenko, Vitali and Kleider, Mitja and Koke, Christoph and Kononov, Alexander and Mauch, Christian and Muller, Eric and Muller, Paul and Partzsch, Johannes and Petrovici, Mihai A. and Schiefer, Stefan and Scholze, Stefan and Thanasoulis, Vasilis and Vogginger, Bernhard and Legenstein, Robert and Maass, Wolfgang and Mayr, Christian and Schuffny, Rene and Schemmel, Johannes and Meier, Karlheinz},
	urldate = {2019-04-04},
	date = {2017-05},
	langid = {english},
	file = {Schmitt et al. - 2017 - Neuromorphic hardware in the loop Training a deep.pdf:/home/danielsan/Zotero/storage/HRP5M6SY/Schmitt et al. - 2017 - Neuromorphic hardware in the loop Training a deep.pdf:application/pdf}
}

@book{petrovici_form_2016,
	location = {Cham},
	title = {Form Versus Function: Theory and Models for Neuronal Substrates},
	isbn = {978-3-319-39551-7 978-3-319-39552-4},
	url = {http://link.springer.com/10.1007/978-3-319-39552-4},
	series = {Springer Theses},
	shorttitle = {Form Versus Function},
	publisher = {Springer International Publishing},
	author = {Petrovici, Mihai Alexandru},
	urldate = {2019-04-04},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-39552-4},
	file = {Petrovici - 2016 - Form Versus Function Theory and Models for Neuron.pdf:/home/danielsan/Zotero/storage/L7VDR2RY/Petrovici - 2016 - Form Versus Function Theory and Models for Neuron.pdf:application/pdf}
}

@article{wunderlich_demonstrating_2019,
	title = {Demonstrating Advantages of Neuromorphic Computation: A Pilot Study},
	volume = {13},
	issn = {1662-453X},
	url = {http://arxiv.org/abs/1811.03618},
	doi = {10.3389/fnins.2019.00260},
	shorttitle = {Demonstrating Advantages of Neuromorphic Computation},
	abstract = {Neuromorphic devices represent an attempt to mimic aspects of the brain’s architecture and dynamics with the aim of replicating its hallmark functional capabilities in terms of computational power, robust learning and energy efﬁciency. We employ a single-chip prototype of the {BrainScaleS} 2 neuromorphic system to implement a proof-of-concept demonstration of reward-modulated spike-timing-dependent plasticity in a spiking network that learns to play a simpliﬁed version of the Pong video game by smooth pursuit. This system combines an electronic mixed-signal substrate for emulating neuron and synapse dynamics with an embedded digital processor for on-chip learning, which in this work also serves to simulate the virtual environment and learning agent. The analog emulation of neuronal membrane dynamics enables a 1000-fold acceleration with respect to biological real-time, with the entire chip operating on a power budget of 57 {mW}. Compared to an equivalent simulation using state-of-the-art software, the on-chip emulation is at least one order of magnitude faster and three orders of magnitude more energy-efﬁcient. We demonstrate how on-chip learning can mitigate the effects of ﬁxed-pattern noise, which is unavoidable in analog substrates, while making use of temporal variability for action exploration. Learning compensates imperfections of the physical substrate, as manifested in neuronal parameter variability, by adapting synaptic weights to match respective excitability of individual neurons.},
	journaltitle = {Frontiers in Neuroscience},
	author = {Wunderlich, Timo and Kungl, Akos F. and Müller, Eric and Hartel, Andreas and Stradmann, Yannik and Aamir, Syed Ahmed and Grübl, Andreas and Heimbrecht, Arthur and Schreiber, Korbinian and Stöckel, David and Pehle, Christian and Billaudelle, Sebastian and Kiene, Gerd and Mauch, Christian and Schemmel, Johannes and Meier, Karlheinz and Petrovici, Mihai A.},
	urldate = {2019-04-04},
	date = {2019-03-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1811.03618},
	keywords = {Computer Science - Emerging Technologies, Computer Science - Neural and Evolutionary Computing},
	file = {Wunderlich et al. - 2019 - Demonstrating Advantages of Neuromorphic Computati.pdf:/home/danielsan/Zotero/storage/D5DUX5R2/Wunderlich et al. - 2019 - Demonstrating Advantages of Neuromorphic Computati.pdf:application/pdf}
}

@article{al-dabbagh_parallel_quicksort_algorithm_using_openm_2016,
	title = {Parallel\_Quicksort\_Algorithm\_using\_OpenM},
	url = {https://figshare.com/articles/Parallel_Quicksort_Algorithm_using_OpenM/3470033},
	doi = {10.6084/m9.figshare.3470033},
	abstract = {In this paper we aims to parallelization the Quicksort algorithm using multithreading ({OpenMP}) {\textless}br{\textgreater}platform. ‎The proposed method examined on two standard dataset (‎File 1: Hamlet.txt 180 {KB} and File 2: {\textless}br{\textgreater}Moby ‎Dick.txt ‎‎1.18 {MB}) ‎ with different number of threads. The fundamental idea of the proposed algorithm {\textless}br{\textgreater}is to creating many additional temporary sub-arrays according to a number of ‎characters in each word, the {\textless}br{\textgreater}sizes of each one of these sub-arrays are adopted based on a number of ‎elements with the exact same number {\textless}br{\textgreater}of characters in the input array. The elements of the input ‎datasets is distributing into these temporary sub-{\textless}br{\textgreater}arrays depending on the number of characters in each ‎word.‎ ‎As a conclusion, the experimental results of this {\textless}br{\textgreater}study  reveal  that  the  performance  of  parallelization  the  proposed  ‎Quicksort  algorithm  has  shown {\textless}br{\textgreater}improvement  when  compared  ‎to  the  sequential  Quicksort  algorithm  by  ‎delivering  improved  Execution {\textless}br{\textgreater}Time, ‎Speedup and Efficiency.},
	journaltitle = {Figshare},
	author = {{AL}-Dabbagh, Sinan},
	urldate = {2019-03-25},
	date = {2016},
	langid = {english},
	file = {AL-Dabbagh - 2016 - Parallel_Quicksort_Algorithm_using_OpenM.pdf:/home/danielsan/Zotero/storage/CZN4VVE7/AL-Dabbagh - 2016 - Parallel_Quicksort_Algorithm_using_OpenM.pdf:application/pdf}
}

@inproceedings{basu_deepsat:_2015,
	location = {Bellevue, Washington},
	title = {{DeepSat}: a learning framework for satellite imagery},
	isbn = {978-1-4503-3967-4},
	url = {http://dl.acm.org/citation.cfm?doid=2820783.2820816},
	doi = {10.1145/2820783.2820816},
	shorttitle = {{DeepSat}},
	abstract = {Satellite image classiﬁcation is a challenging problem that lies at the crossroads of remote sensing, computer vision, and machine learning. Due to the high variability inherent in satellite data, most of the current object classiﬁcation approaches are not suitable for handling satellite datasets. The progress of satellite image analytics has also been inhibited by the lack of a single labeled highresolution dataset with multiple class labels. The contributions of this paper are twofold – (1) ﬁrst, we present two new satellite datasets called {SAT}-4 and {SAT}-6, and (2) then, we propose a classiﬁcation framework that extracts features from an input image, normalizes them and feeds the normalized feature vectors to a Deep Belief Network for classiﬁcation. On the {SAT}-4 dataset, our best network produces a classiﬁcation accuracy of 97.95\% and outperforms three state-of-the-art object recognition algorithms, namely Deep Belief Networks, Convolutional Neural Networks and Stacked Denoising Autoencoders by ∼11\%. On {SAT}-6, it produces a classiﬁcation accuracy of 93.9\% and outperforms the other algorithms by ∼15\%. Comparative studies with a Random Forest classiﬁer show the advantage of an unsupervised learning approach over traditional supervised learning techniques. A statistical analysis based on Distribution Separability Criterion and Intrinsic Dimensionality Estimation substantiates the effectiveness of our approach in learning better representations for satellite imagery.},
	eventtitle = {the 23rd {SIGSPATIAL} International Conference},
	pages = {1--10},
	booktitle = {Proceedings of the 23rd {SIGSPATIAL} International Conference on Advances in Geographic Information Systems - {GIS} '15},
	publisher = {{ACM} Press},
	author = {Basu, Saikat and Ganguly, Sangram and Mukhopadhyay, Supratik and {DiBiano}, Robert and Karki, Manohar and Nemani, Ramakrishna},
	urldate = {2019-11-07},
	date = {2015},
	langid = {english},
	file = {Basu et al. - 2015 - DeepSat a learning framework for satellite imager.pdf:/home/danielsan/Zotero/storage/GMTIHY4J/Basu et al. - 2015 - DeepSat a learning framework for satellite imager.pdf:application/pdf}
}

@article{helber_eurosat:_2019,
	title = {{EuroSAT}: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification},
	volume = {12},
	issn = {1939-1404, 2151-1535},
	doi = {10.1109/JSTARS.2019.2918242},
	shorttitle = {{EuroSAT}},
	abstract = {In this paper, we present a patch-based land use and land cover classification approach using Sentinel-2 satellite images. The Sentinel-2 satellite images are openly and freely accessible, and are provided in the earth observation program Copernicus. We present a novel dataset, based on these images that covers 13 spectral bands and is comprised of ten classes with a total of 27 000 labeled and geo-referenced images. Benchmarks are provided for this novel dataset with its spectral bands using state-of-the-art deep convolutional neural networks. An overall classification accuracy of 98.57\% was achieved with the proposed novel dataset. The resulting classification system opens a gate toward a number of earth observation applications. We demonstrate how this classification system can be used for detecting land use and land cover changes, and how it can assist in improving geographical maps. The geo-referenced dataset {EuroSAT} is made publicly available at https://github.com/phelber/eurosat.},
	pages = {2217--2226},
	number = {7},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
	date = {2019-07},
	keywords = {learning (artificial intelligence), Benchmark testing, convolutional neural nets, Dataset, deep convolutional neural network, deep convolutional neural networks, deep learning, deep learning benchmark, Earth, earth observation, Earth observation program Copernicus, feature extraction, Feature extraction, geo-referenced dataset {EuroSAT}, geo-referenced images, geographical maps, geophysical image processing, image classification, land cover, land cover changes, land cover classification, land cover classification approach, land use, land use classification, machine learning, Machine learning, patch-based land use, remote sensing, Remote sensing, satellite image classification, satellite images, Satellites, Sentinel-2 satellite images, Spatial resolution},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/ZTKGW4SN/8736785.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/6S83MNSM/Helber et al. - 2019 - EuroSAT A Novel Dataset and Deep Learning Benchma.pdf:application/pdf}
}

@article{trivedi_low-level_1986,
	title = {Low-Level Segmentation of Aerial Images with Fuzzy Clustering},
	volume = {16},
	issn = {0018-9472, 2168-2909},
	doi = {10.1109/TSMC.1986.289264},
	abstract = {A low-level segmentation methodology based upon fuzzy clustering principles is developed. The approach utilizes region growing concepts and a pyramid data structure for the hierarchical analysis of aerial images. It is assumed that measurement vectors corresponding to perceptually homogeneous regions cluster together in the measurement space. The fuzzy c-means ({FCM}) clustering algorithm is used in the formulation. Utilization of the fuzzy partitioning allows one to derive a correspondence between the cluster membership function values and (the proportions of) the classes constituting a region. Thus cluster membership values can be used to split mixture regions into smaller regions at a higher resolution level. The feasibility of the methodology is evaluated using a three-channel Landsat image. The results show that the {FCM} clustering can be used in the single-level segmentation; and that cluster membership function values derived using this algorithm can be utilized effectively as indicators of region homogeneity.},
	pages = {589--598},
	number = {4},
	journaltitle = {{IEEE} Transactions on Systems, Man, and Cybernetics},
	author = {Trivedi, Mohan M. and Bezdek, James C.},
	date = {1986-07},
	keywords = {Cameras, Clustering algorithms, Computer vision, Image analysis, Image processing, Image segmentation, Machine vision, Robot sensing systems, Robot vision systems, Service robots},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/BFGYUHDB/4075616.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/GJ2TB8EQ/Trivedi and Bezdek - 1986 - Low-Level Segmentation of Aerial Images with Fuzzy.pdf:application/pdf}
}

@article{marmanis_semantic_2016,
	title = {{SEMANTIC} {SEGMENTATION} {OF} {AERIAL} {IMAGES} {WITH} {AN} {ENSEMBLE} {OF} {CNNS}},
	volume = {{III}-3},
	issn = {2194-9050},
	url = {http://www.isprs-ann-photogramm-remote-sens-spatial-inf-sci.net/III-3/473/2016/isprs-annals-III-3-473-2016.pdf},
	doi = {10.5194/isprsannals-III-3-473-2016},
	abstract = {This paper describes a deep learning approach to semantic segmentation of very high resolution (aerial) images. Deep neural architectures hold the promise of end-to-end learning from raw images, making heuristic feature design obsolete. Over the last decade this idea has seen a revival, and in recent years deep convolutional neural networks ({CNNs}) have emerged as the method of choice for a range of image interpretation tasks like visual recognition and object detection. Still, standard {CNNs} do not lend themselves to per-pixel semantic segmentation, mainly because one of their fundamental principles is to gradually aggregate information over larger and larger image regions, making it hard to disentangle contributions from different pixels. Very recently two extensions of the {CNN} framework have made it possible to trace the semantic information back to a precise pixel position: deconvolutional network layers undo the spatial downsampling, and Fully Convolution Networks ({FCNs}) modify the fully connected classiﬁcation layers of the network in such a way that the location of individual activations remains explicit. We design a {FCN} which takes as input intensity and range data and, with the help of aggressive deconvolution and recycling of early network layers, converts them into a pixelwise classiﬁcation at full resolution. We discuss design choices and intricacies of such a network, and demonstrate that an ensemble of several networks achieves excellent results on challenging data such as the {ISPRS} semantic labeling benchmark, using only the raw data as input.},
	pages = {473--480},
	journaltitle = {{ISPRS} Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Marmanis, D. and Wegner, J. D. and Galliani, S. and Schindler, K. and Datcu, M. and Stilla, U.},
	urldate = {2019-11-07},
	date = {2016-06-06},
	langid = {english},
	file = {Marmanis et al. - 2016 - SEMANTIC SEGMENTATION OF AERIAL IMAGES WITH AN ENS.pdf:/home/danielsan/Zotero/storage/GQILDPFV/Marmanis et al. - 2016 - SEMANTIC SEGMENTATION OF AERIAL IMAGES WITH AN ENS.pdf:application/pdf}
}

@article{karkus_particle_2018,
	title = {Particle Filter Networks with Application to Visual Localization},
	url = {http://arxiv.org/abs/1805.08975},
	abstract = {Particle ﬁltering is a powerful approach to sequential state estimation and ﬁnds application in many domains, including robot localization, object tracking, etc. To apply particle ﬁltering in practice, a critical challenge is to construct probabilistic system models, especially for systems with complex dynamics or rich sensory inputs such as camera images. This paper introduces the Particle Filter Network ({PFnet}), which encodes both a system model and a particle ﬁlter algorithm in a single neural network. The {PF}-net is fully differentiable and trained end-to-end from data. Instead of learning a generic system model, it learns a model optimized for the particle ﬁlter algorithm. We apply the {PF}-net to a visual localization task, in which a robot must localize in a rich 3-D world, using only a schematic 2-D ﬂoor map. In simulation experiments, {PF}-net consistently outperforms alternative learning architectures, as well as a traditional model-based method, under a variety of sensor inputs. Further, {PF}-net generalizes well to new, unseen environments.},
	journaltitle = {{arXiv}:1805.08975 [cs, stat]},
	author = {Karkus, Peter and Hsu, David and Lee, Wee Sun},
	urldate = {2019-11-07},
	date = {2018-10-25},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1805.08975},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	file = {Karkus et al. - 2018 - Particle Filter Networks with Application to Visua.pdf:/home/danielsan/Zotero/storage/8B2F5VRV/Karkus et al. - 2018 - Particle Filter Networks with Application to Visua.pdf:application/pdf}
}

@incollection{hutchison_introduction_2012,
	location = {Berlin, Heidelberg},
	title = {An Introduction to Random Forests for Multi-class Object Detection},
	volume = {7474},
	isbn = {978-3-642-34090-1 978-3-642-34091-8},
	url = {http://link.springer.com/10.1007/978-3-642-34091-8_11},
	abstract = {Object detection in large-scale real-world scenes requires eﬃcient multi-class detection approaches. Random forests have been shown to handle large training datasets and many classes for object detection eﬃciently. The most prominent example is the commercial application of random forests for gaming [36]. In this chapter, we describe the general framework of random forests for multi-class object detection in images and give an overview of recent developments and implementation details that are relevant for practitioners.},
	pages = {243--263},
	booktitle = {Outdoor and Large-Scale Real-World Scene Analysis},
	publisher = {Springer Berlin Heidelberg},
	author = {Gall, Juergen and Razavi, Nima and Van Gool, Luc},
	editor = {Dellaert, Frank and Frahm, Jan-Michael and Pollefeys, Marc and Leal-Taixé, Laura and Rosenhahn, Bodo},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-11-08},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-34091-8_11},
	file = {Gall et al. - 2012 - An Introduction to Random Forests for Multi-class .pdf:/home/danielsan/Zotero/storage/2C43ZS3L/Gall et al. - 2012 - An Introduction to Random Forests for Multi-class .pdf:application/pdf}
}

@inproceedings{hudjakov_aerial_2009-1,
	location = {Istanbul, Turkey},
	title = {Aerial imagery terrain classification for long-range autonomous navigation},
	isbn = {978-1-4244-4209-6},
	url = {http://ieeexplore.ieee.org/document/5326104/},
	doi = {10.1109/ISOT.2009.5326104},
	abstract = {The paper presents a method of terrain classification and path planning for unmanned ground vehicles. The terrain classification is done on imagery that is acquired from {UAV} (Unmanned Aerial Vehicle) and is used for {UGV} (Unmanned Ground Vehicle) path planning thus introducing collaboration capabilities to the system of two. The system complements {UGV} on-board navigation system by increasing its perception distance and providing long-range path planning capability.},
	eventtitle = {2009 International Symposium on Optomechatronic Technologies ({ISOT} 2009)},
	pages = {88--91},
	booktitle = {2009 International Symposium on Optomechatronic Technologies},
	publisher = {{IEEE}},
	author = {Hudjakov, Robert and Tamre, Mart},
	urldate = {2019-11-21},
	date = {2009-09},
	langid = {english},
	file = {Hudjakov and Tamre - 2009 - Aerial imagery terrain classification for long-ran.pdf:/home/danielsan/Zotero/storage/F2HER8G8/Hudjakov and Tamre - 2009 - Aerial imagery terrain classification for long-ran.pdf:application/pdf}
}

@inproceedings{rublee_orb:_2011,
	location = {Barcelona, Spain},
	title = {{ORB}: An efficient alternative to {SIFT} or {SURF}},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	url = {http://ieeexplore.ieee.org/document/6126544/},
	doi = {10.1109/ICCV.2011.6126544},
	shorttitle = {{ORB}},
	abstract = {Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on {BRIEF}, called {ORB}, which is rotation invariant and resistant to noise. We demonstrate through experiments how {ORB} is at two orders of magnitude faster than {SIFT}, while performing as well in many situations. The efﬁciency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
	eventtitle = {2011 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {2564--2571},
	booktitle = {2011 International Conference on Computer Vision},
	publisher = {{IEEE}},
	author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
	urldate = {2019-11-21},
	date = {2011-11},
	langid = {english},
	file = {Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:/home/danielsan/Zotero/storage/9PENBF67/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:application/pdf}
}

@inproceedings{redmon_you_2016,
	location = {Las Vegas, {NV}, {USA}},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	isbn = {978-1-4673-8851-1},
	url = {http://ieeexplore.ieee.org/document/7780460/},
	doi = {10.1109/CVPR.2016.91},
	shorttitle = {You Only Look Once},
	abstract = {We present {YOLO}, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
	eventtitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {779--788},
	booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	urldate = {2019-11-22},
	date = {2016-06},
	langid = {english},
	file = {Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:/home/danielsan/Zotero/storage/B82H8PD2/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf:application/pdf}
}

@online{noauthor_visual_nodate,
	title = {visual localization of uav using ml},
	url = {https://www.overleaf.com/project/5dc4038d85adaf00019cf2cc},
	abstract = {An online {LaTeX} editor that's easy to use. No installation, real-time collaboration, version control, hundreds of {LaTeX} templates, and more.},
	urldate = {2019-11-22},
	langid = {english},
	file = {Snapshot:/home/danielsan/Zotero/storage/BYRXCH2Y/5dc4038d85adaf00019cf2cc.html:text/html}
}

@incollection{fleet_30hz_2014,
	location = {Cham},
	title = {30Hz Object Detection with {DPM} V5},
	volume = {8689},
	isbn = {978-3-319-10589-5 978-3-319-10590-1},
	url = {http://link.springer.com/10.1007/978-3-319-10590-1_5},
	abstract = {We describe an implementation of the Deformable Parts Model [1] that operates in a user-deﬁned time-frame. Our implementation uses a variety of mechanism to trade-oﬀ speed against accuracy. Our implementation can detect all 20 {PASCAL} 2007 objects simultaneously at 30Hz with an {mAP} of 0.26. At 15Hz, its {mAP} is 0.30; and at 100Hz, its {mAP} is 0.16. By comparison the reference implementation of [1] runs at 0.07Hz and {mAP} of 0.33 and a fast {GPU} implementation runs at 1Hz. Our technique is over an order of magnitude faster than the previous fastest {DPM} implementation. Our implementation exploits a series of important speedup mechanisms. We use the cascade framework of [3] and the vector quantization technique of [2]. To speed up feature computation, we compute {HOG} features at few scales, and apply many interpolated templates. A hierarchical vector quantization method is used to compress {HOG} features for fast template evaluation. An object proposal step uses hash-table methods to identify locations where evaluating templates would be most useful; these locations are inserted into a priority queue, and processed in a detection phase. Both proposal and detection phases have an any-time property. Our method applies to legacy templates, and no retraining is required.},
	pages = {65--79},
	booktitle = {Computer Vision – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Sadeghi, Mohammad Amin and Forsyth, David},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	urldate = {2019-11-22},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-10590-1_5},
	file = {Sadeghi and Forsyth - 2014 - 30Hz Object Detection with DPM V5.pdf:/home/danielsan/Zotero/storage/2ABRNLNR/Sadeghi and Forsyth - 2014 - 30Hz Object Detection with DPM V5.pdf:application/pdf}
}

@inproceedings{lowe_object_1999,
	location = {Kerkyra, Greece},
	title = {Object recognition from local scale-invariant features},
	isbn = {978-0-7695-0164-2},
	url = {http://ieeexplore.ieee.org/document/790410/},
	doi = {10.1109/ICCV.1999.790410},
	abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and afﬁne or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efﬁciently detected through a staged ﬁltering approach that identiﬁes stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest-neighbor indexing method that identiﬁes candidate object matches. Final veriﬁcation of each match is achieved by ﬁnding a low-residual least-squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially-occluded images with a computation time of under 2 seconds.},
	eventtitle = {Proceedings of the Seventh {IEEE} International Conference on Computer Vision},
	pages = {1150--1157 vol.2},
	booktitle = {Proceedings of the Seventh {IEEE} International Conference on Computer Vision},
	publisher = {{IEEE}},
	author = {Lowe, D.G.},
	urldate = {2019-11-22},
	date = {1999},
	langid = {english},
	file = {Lowe - 1999 - Object recognition from local scale-invariant feat.pdf:/home/danielsan/Zotero/storage/6Q847YQC/Lowe - 1999 - Object recognition from local scale-invariant feat.pdf:application/pdf}
}

@article{uijlings_selective_2013,
	title = {Selective Search for Object Recognition},
	volume = {104},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-013-0620-5},
	doi = {10.1007/s11263-013-0620-5},
	abstract = {This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99 \% recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi. unitn.it/{\textasciitilde}uijlings/{SelectiveSearch}.html).},
	pages = {154--171},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	author = {Uijlings, J. R. R. and van de Sande, K. E. A. and Gevers, T. and Smeulders, A. W. M.},
	urldate = {2019-11-22},
	date = {2013-09},
	langid = {english},
	file = {Uijlings et al. - 2013 - Selective Search for Object Recognition.pdf:/home/danielsan/Zotero/storage/SAHKV8BN/Uijlings et al. - 2013 - Selective Search for Object Recognition.pdf:application/pdf}
}

@article{gould_region-based_nodate,
	title = {Region-based Segmentation and Object Detection},
	abstract = {Object detection and multi-class image segmentation are two closely related tasks that can be greatly improved when solved jointly by feeding information from one task to the other [10, 11]. However, current state-of-the-art models use a separate representation for each task making joint inference clumsy and leaving the classiﬁcation of many parts of the scene ambiguous.},
	pages = {9},
	author = {Gould, Stephen and Gao, Tianshi and Koller, Daphne},
	langid = {english},
	file = {Gould et al. - Region-based Segmentation and Object Detection.pdf:/home/danielsan/Zotero/storage/ZU2JHKPJ/Gould et al. - Region-based Segmentation and Object Detection.pdf:application/pdf}
}

@incollection{fleet_edge_2014,
	location = {Cham},
	title = {Edge Boxes: Locating Object Proposals from Edges},
	volume = {8693},
	isbn = {978-3-319-10601-4 978-3-319-10602-1},
	url = {http://link.springer.com/10.1007/978-3-319-10602-1_26},
	shorttitle = {Edge Boxes},
	abstract = {The use of object proposals is an eﬀective recent approach for increasing the computational eﬃciency of object detection. We propose a novel method for generating object bounding box proposals using edges. Edges provide a sparse yet informative representation of an image. Our main observation is that the number of contours that are wholly contained in a bounding box is indicative of the likelihood of the box containing an object. We propose a simple box objectness score that measures the number of edges that exist in the box minus those that are members of contours that overlap the box’s boundary. Using eﬃcient data structures, millions of candidate boxes can be evaluated in a fraction of a second, returning a ranked set of a few thousand top-scoring proposals. Using standard metrics, we show results that are signiﬁcantly more accurate than the current state-of-the-art while being faster to compute. In particular, given just 1000 proposals we achieve over 96\% object recall at overlap threshold of 0.5 and over 75\% recall at the more challenging overlap of 0.7. Our approach runs in 0.25 seconds and we additionally demonstrate a near real-time variant with only minor loss in accuracy.},
	pages = {391--405},
	booktitle = {Computer Vision – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zitnick, C. Lawrence and Dollár, Piotr},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	urldate = {2019-11-22},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-10602-1_26},
	file = {Zitnick and Dollár - 2014 - Edge Boxes Locating Object Proposals from Edges.pdf:/home/danielsan/Zotero/storage/GRTQKTM5/Zitnick and Dollár - 2014 - Edge Boxes Locating Object Proposals from Edges.pdf:application/pdf}
}

@article{shinn-ying_ho_intelligent_2004,
	title = {Intelligent evolutionary algorithms for large parameter optimization problems},
	volume = {8},
	issn = {1941-0026},
	doi = {10.1109/TEVC.2004.835176},
	abstract = {This work proposes two intelligent evolutionary algorithms {IEA} and {IMOEA} using a novel intelligent gene collector ({IGC}) to solve single and multiobjective large parameter optimization problems, respectively. {IGC} is the main phase in an intelligent recombination operator of {IEA} and {IMOEA}. Based on orthogonal experimental design, {IGC} uses a divide-and-conquer approach, which consists of adaptively dividing two individuals of parents into N pairs of gene segments, economically identifying the potentially better one of two gene segments of each pair, and systematically obtaining a potentially good approximation to the best one of all combinations using at most 2N fitness evaluations. {IMOEA} utilizes a novel generalized Pareto-based scale-independent fitness function for efficiently finding a set of Pareto-optimal solutions to a multiobjective optimization problem. The advantages of {IEA} and {IMOEA} are their simplicity, efficiency, and flexibility. It is shown empirically that {IEA} and {IMOEA} have high performance in solving benchmark functions comprising many parameters, as compared with some existing {EAs}.},
	pages = {522--541},
	number = {6},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {Shinn-Ying Ho and Li-Sun Shu and Jian-Hung Chen},
	date = {2004-12},
	keywords = {Genetic algorithms, 2N fitness evaluations, Councils, Design for experiments, Design optimization, divide and conquer methods, divide-and-conquer approach, economical identification, Evolution (biology), Evolutionary algorithm ({EA}), evolutionary computation, Evolutionary computation, gene segments, genetic algorithm ({GA}), Genetic mutations, Genetic programming, intelligent evolutionary algorithms, intelligent gene collector, intelligent gene collector ({IGC}), intelligent recombination operator, large parameter optimization problem, multiobjective optimization, multiobjective optimization problem, Optimization methods, orthogonal experimental design, Pareto-based scale-independent fitness function, Pareto-optimal solution},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/ADKT4R33/1369245.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/2M6YSV8A/Shinn-Ying Ho et al. - 2004 - Intelligent evolutionary algorithms for large para.pdf:application/pdf}
}

@article{ji_invariant_2019,
	title = {Invariant Information Clustering for Unsupervised Image Classification and Segmentation},
	url = {http://arxiv.org/abs/1807.06653},
	abstract = {We present a novel clustering objective that learns a neural network classifier from scratch, given only unlabelled data samples. The model discovers clusters that accurately match semantic classes, achieving state-of-the-art results in eight unsupervised clustering benchmarks spanning image classification and segmentation. These include {STL}10, an unsupervised variant of {ImageNet}, and {CIFAR}10, where we significantly beat the accuracy of our closest competitors by 6.6 and 9.5 absolute percentage points respectively. The method is not specialised to computer vision and operates on any paired dataset samples; in our experiments we use random transforms to obtain a pair from each image. The trained network directly outputs semantic labels, rather than high dimensional representations that need external processing to be usable for semantic clustering. The objective is simply to maximise mutual information between the class assignments of each pair. It is easy to implement and rigorously grounded in information theory, meaning we effortlessly avoid degenerate solutions that other clustering methods are susceptible to. In addition to the fully unsupervised mode, we also test two semi-supervised settings. The first achieves 88.8\% accuracy on {STL}10 classification, setting a new global state-of-the-art over all existing methods (whether supervised, semi-supervised or unsupervised). The second shows robustness to 90\% reductions in label coverage, of relevance to applications that wish to make use of small amounts of labels. github.com/xu-ji/{IIC}},
	journaltitle = {{arXiv}:1807.06653 [cs]},
	author = {Ji, Xu and Henriques, João F. and Vedaldi, Andrea},
	urldate = {2019-11-22},
	date = {2019-08-22},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1807.06653},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:/home/danielsan/Zotero/storage/4IAX8679/Ji et al. - 2019 - Invariant Information Clustering for Unsupervised .pdf:application/pdf}
}

@article{strydom_visual_2014,
	title = {Visual Odometry: Autonomous {UAV} Navigation using Optic Flow and Stereo},
	abstract = {Visual odometry is vital to the future of mobile robotics. In this paper, we demonstrate a method that combines information from optic flow and stereo to estimate and control the current position of a quadrotor along a pre-defined trajectory. The absolute translation in 3D is computed by combining the optic flow measurements between successive frames and stereo-based height over ground. The current 3D position, as estimated from path integration of the incremental translations, is controlled in closed loop to follow the prescribed trajectory. The performance of the system is evaluated by measuring the error between the initial and final positions in closed circuits. This error is approximately 1.7\% of the total path length.},
	pages = {10},
	author = {Strydom, Reuben and Thurrowgood, Saul and Srinivasan, Mandyam V},
	date = {2014},
	langid = {english},
	file = {Strydom et al. - 2014 - Visual Odometry Autonomous UAV Navigation using O.pdf:/home/danielsan/Zotero/storage/75SSW67Z/Strydom et al. - 2014 - Visual Odometry Autonomous UAV Navigation using O.pdf:application/pdf}
}

@inproceedings{yol_vision-based_2014,
	title = {Vision-based absolute localization for unmanned aerial vehicles},
	doi = {10.1109/IROS.2014.6943040},
	abstract = {This paper presents a method for localizing an Unmanned Aerial Vehicle ({UAV}) using georeferenced aerial images. Easily maneuverable and more and more affordable, {UAVs} have become a real center of interest. In the last few years, their utilization has significantly increased. Today, they are used for multiple tasks such as navigation, transportation or vigilance. Nevertheless, the success of these tasks could not be possible without a highly accurate localization which can, unfortunately be often laborious. Here we provide a multiple usage localization algorithm based on vision only. However, a major drawback with vision-based algorithms is the lack of robustness. Most of the approaches are sensitive to scene variations (like season or environment changes) due to the fact that they use the Sum of Squared Differences ({SSD}). To prevent that, we choose to use the Mutual Information ({MI}) which is very robust toward local and global scene variations. However, dense approaches are often related to drift disadvantages. Here, we solve this problem by using georeferenced images. The localization algorithm has been implemented and experimental results are presented demonstrating the localization of a hexarotor {UAV} fitted with a downward looking camera during real flight tests.},
	eventtitle = {2014 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	pages = {3429--3434},
	booktitle = {2014 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Yol, Aurélien and Delabarre, Bertrand and Dame, Amaury and Dartois, Jean-Émile and Marchand, Eric},
	date = {2014-09},
	note = {{ISSN}: 2153-0866},
	keywords = {Robustness, Cameras, autonomous aerial vehicles, camera, cameras, Estimation, flight tests, georeferenced aerial images, georeferenced images, Global Positioning System, global scene variations, image registration, Image registration, local scene variations, {MI}, multiple usage localization algorithm, mutual information, Mutual information, robot vision, {UAV}, unmanned aerial vehicles, vision-based absolute localization},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/I7NMU8Z2/6943040.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/PJSAU3RY/Yol et al. - 2014 - Vision-based absolute localization for unmanned ae.pdf:application/pdf}
}

@article{carroll_vulnerability_2003,
	title = {Vulnerability Assessment of the U.S. Transportation Infrastructure that Relies on the Global Positioning System},
	volume = {56},
	issn = {0373-4633, 1469-7785},
	url = {https://www.cambridge.org/core/product/identifier/S0373463303002273/type/journal_article},
	doi = {10.1017/S0373463303002273},
	pages = {185--193},
	number = {2},
	journaltitle = {Journal of Navigation},
	author = {Carroll, James V.},
	urldate = {2019-11-22},
	date = {2003-05},
	langid = {english},
	file = {Carroll - 2003 - Vulnerability Assessment of the U.S. Transportatio.pdf:/home/danielsan/Zotero/storage/ET3CZZ7E/Carroll - 2003 - Vulnerability Assessment of the U.S. Transportatio.pdf:application/pdf}
}

@inproceedings{zheng_rotation_2014,
	title = {Rotation and affine-invariant {SIFT} descriptor for matching {UAV} images with satellite images},
	doi = {10.1109/CGNCC.2014.7007582},
	abstract = {Image matching is a key issue in Vision-Based {UAV} navigation problems. This paper presents an affine and rotation-invariant {SIFT} features descriptor for matching {UAV} image with satellite images. The {SIFT} and {ASIFT} algorithm are nowadays widely applied for robust image matching, but it also has a high computational complexity. {SURF} is used for real-time {UAV} position estimation but is not satisfied for affine invariant. We introduce the new {SIFT} feature descriptor based on pie chart region. This descriptor is invariant for rotation, affine, scale and the dimension of the feature vector is relatively reduced. Therefore, this method satisfies robustness and low computational complexity. Experiments show that this method can improve the matching accuracy and robustness.},
	eventtitle = {Proceedings of 2014 {IEEE} Chinese Guidance, Navigation and Control Conference},
	pages = {2624--2628},
	booktitle = {Proceedings of 2014 {IEEE} Chinese Guidance, Navigation and Control Conference},
	author = {Zheng, Mingguo and Wu, Chengdong and Chen, Dongyue and Meng, Zhexiu},
	date = {2014-08},
	note = {{ISSN}: null},
	keywords = {satellite images, Satellites, autonomous aerial vehicles, affine-invariant {SIFT} feature descriptor, {ASIFT} algorithm, computer vision, Educational institutions, image matching, Image matching, pie chart region, real-time {UAV} position estimation, rotation-invariant {SIFT} features descriptor, Satellite navigation systems, Shape, {SURF}, transforms, Transforms, {UAV} image matching, unmanned aerial vehicle, Vectors, vision-based {UAV} navigation problems},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/P3T69NUC/7007582.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/5ICKA4IQ/Zheng et al. - 2014 - Rotation and affine-invariant SIFT descriptor for .pdf:application/pdf}
}

@incollection{hutchison_brief:_2010,
	location = {Berlin, Heidelberg},
	title = {{BRIEF}: Binary Robust Independent Elementary Features},
	volume = {6314},
	isbn = {978-3-642-15560-4 978-3-642-15561-1},
	url = {http://link.springer.com/10.1007/978-3-642-15561-1_56},
	shorttitle = {{BRIEF}},
	abstract = {We propose to use binary strings as an eﬃcient feature point descriptor, which we call {BRIEF}. We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity diﬀerence tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very eﬃcient to compute, instead of the L2 norm as is usually done.},
	pages = {778--792},
	booktitle = {Computer Vision – {ECCV} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	urldate = {2019-11-22},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-15561-1_56},
	file = {Hutchison et al. - 2010 - BRIEF Binary Robust Independent Elementary Featur.pdf:/home/danielsan/Zotero/storage/Q55JAPHX/Hutchison et al. - 2010 - BRIEF Binary Robust Independent Elementary Featur.pdf:application/pdf}
}

@inproceedings{khan_visual_2012,
	title = {Visual terrain classification by flying robots},
	doi = {10.1109/ICRA.2012.6224988},
	abstract = {In this paper we investigate the effectiveness of {SURF} features for visual terrain classification for outdoor flying robots. A quadrocopter fitted with a single camera is flown over different terrains to take images of the ground below. Each image is divided into a grid and {SURF} features are calculated at grid intersections. A classifier is then used to learn to differentiate between different terrain types. Classification results of the {SURF} descriptor are compared with results from other texture descriptors like Local Binary Patterns and Local Ternary Patterns. Six different terrain types are considered in this approach. Random forests are used for classification on each descriptor. It is shown that {SURF} features perform better than other descriptors at higher resolutions.},
	eventtitle = {2012 {IEEE} International Conference on Robotics and Automation},
	pages = {498--503},
	booktitle = {2012 {IEEE} International Conference on Robotics and Automation},
	author = {Khan, Yasir Niaz and Masselli, Andreas and Zell, Andreas},
	date = {2012-05},
	note = {{ISSN}: 1050-4729},
	keywords = {mobile robots, Feature extraction, image classification, Cameras, Accuracy, control engineering computing, helicopters, Image resolution, image texture, local binary patterns, local ternary patterns, outdoor flying robots, quadrocopter, random forests, Robots, {SURF} features, terrain mapping, texture descriptors, Vegetation, visual terrain classification, Visualization},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/RSNIRKMY/6224988.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/9Q5GQC7B/Khan et al. - 2012 - Visual terrain classification by flying robots.pdf:application/pdf}
}

@article{radovic_object_2017-1,
	title = {Object Recognition in Aerial Images Using Convolutional Neural Networks},
	volume = {3},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2313-433X/3/2/21},
	doi = {10.3390/jimaging3020021},
	abstract = {There are numerous applications of unmanned aerial vehicles ({UAVs}) in the management of civil infrastructure assets. A few examples include routine bridge inspections, disaster management, power line surveillance and traffic surveying. As {UAV} applications become widespread, increased levels of autonomy and independent decision-making are necessary to improve the safety, efficiency, and accuracy of the devices. This paper details the procedure and parameters used for the training of convolutional neural networks ({CNNs}) on a set of aerial images for efficient and automated object recognition. Potential application areas in the transportation field are also highlighted. The accuracy and reliability of {CNNs} depend on the network’s training and the selection of operational parameters. This paper details the {CNN} training procedure and parameter selection. The object recognition results show that by selecting a proper set of parameters, a {CNN} can detect and classify objects with a high level of accuracy (97.5\%) and computational efficiency. Furthermore, using a convolutional neural network implemented in the “{YOLO}” (“You Only Look Once”) platform, objects can be tracked, detected (“seen”), and classified (“comprehended”) from video feeds supplied by {UAVs} in real-time.},
	pages = {21},
	number = {2},
	journaltitle = {Journal of Imaging},
	author = {Radovic, Matija and Adarkwa, Offei and Wang, Qiaosong},
	urldate = {2019-11-22},
	date = {2017-06},
	langid = {english},
	keywords = {convolutional neural networks, object recognition and detection, Unmanned Aerial Vehicle ({UAV})},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/NBBX5CHW/Radovic et al. - 2017 - Object Recognition in Aerial Images Using Convolut.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/WHEBG2IP/htm.html:text/html}
}

@article{oshea_introduction_2015,
	title = {An Introduction to Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1511.08458},
	abstract = {The ﬁeld of machine learning has taken a dramatic twist in recent times, with the rise of the Artiﬁcial Neural Network ({ANN}). These biologically inspired computational models are able to far exceed the performance of previous forms of artiﬁcial intelligence in common machine learning tasks. One of the most impressive forms of {ANN} architecture is that of the Convolutional Neural Network ({CNN}). {CNNs} are primarily used to solve difﬁcult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simpliﬁed method of getting started with {ANNs}.},
	journaltitle = {{arXiv}:1511.08458 [cs]},
	author = {O'Shea, Keiron and Nash, Ryan},
	urldate = {2019-11-22},
	date = {2015-12-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1511.08458},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {O'Shea and Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf:/home/danielsan/Zotero/storage/YW4HK2QC/O'Shea and Nash - 2015 - An Introduction to Convolutional Neural Networks.pdf:application/pdf}
}

@article{breiman_random_2001,
	title = {Random Forests},
	volume = {45},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1010933404324},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	pages = {5--32},
	number = {1},
	journaltitle = {Machine Learning},
	shortjournal = {Machine Learning},
	author = {Breiman, Leo},
	urldate = {2019-11-22},
	date = {2001-10-01},
	langid = {english},
	keywords = {classification, ensemble, regression},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/36YHF3LN/Breiman - 2001 - Random Forests.pdf:application/pdf}
}

@article{lecun_deep_2015-1,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2019-11-22},
	date = {2015-05},
	langid = {english},
	file = {LeCun et al. - 2015 - Deep learning.pdf:/home/danielsan/Zotero/storage/68XCWAHJ/LeCun et al. - 2015 - Deep learning.pdf:application/pdf}
}

@article{ren_faster_2017,
	title = {Faster R-{CNN}: Towards Real-Time Object Detection with Region Proposal Networks},
	volume = {39},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/7485869/},
	doi = {10.1109/TPAMI.2016.2577031},
	shorttitle = {Faster R-{CNN}},
	abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like {SPPnet} [7] and Fast R-{CNN} [5] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network ({RPN}) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An {RPN} is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. {RPNs} are trained end-to-end to generate highquality region proposals, which are used by Fast R-{CNN} for detection. With a simple alternating optimization, {RPN} and Fast R-{CNN} can be trained to share convolutional features. For the very deep {VGG}-16 model [19], our detection system has a frame rate of 5fps (including all steps) on a {GPU}, while achieving state-of-the-art object detection accuracy on {PASCAL} {VOC} 2007 (73.2\% {mAP}) and 2012 (70.4\% {mAP}) using 300 proposals per image. Code is available at https://github.com/{ShaoqingRen}/faster\_rcnn.},
	pages = {1137--1149},
	number = {6},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	urldate = {2019-11-22},
	date = {2017-06-01},
	langid = {english},
	file = {Ren et al. - 2017 - Faster R-CNN Towards Real-Time Object Detection w.pdf:/home/danielsan/Zotero/storage/2XEWC8CM/Ren et al. - 2017 - Faster R-CNN Towards Real-Time Object Detection w.pdf:application/pdf}
}

@incollection{hutchison_brief:_2010-1,
	location = {Berlin, Heidelberg},
	title = {{BRIEF}: Binary Robust Independent Elementary Features},
	volume = {6314},
	isbn = {978-3-642-15560-4 978-3-642-15561-1},
	url = {http://link.springer.com/10.1007/978-3-642-15561-1_56},
	shorttitle = {{BRIEF}},
	abstract = {We propose to use binary strings as an eﬃcient feature point descriptor, which we call {BRIEF}. We show that it is highly discriminative even when using relatively few bits and can be computed using simple intensity diﬀerence tests. Furthermore, the descriptor similarity can be evaluated using the Hamming distance, which is very eﬃcient to compute, instead of the L2 norm as is usually done.},
	pages = {778--792},
	booktitle = {Computer Vision – {ECCV} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	urldate = {2019-11-22},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-15561-1_56},
	file = {Hutchison et al. - 2010 - BRIEF Binary Robust Independent Elementary Featur.pdf:/home/danielsan/Zotero/storage/ALIUVABG/Hutchison et al. - 2010 - BRIEF Binary Robust Independent Elementary Featur.pdf:application/pdf}
}

@article{pei_towards_2019,
	title = {Towards artificial general intelligence with hybrid Tianjic chip architecture},
	volume = {572},
	rights = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1424-8},
	doi = {10.1038/s41586-019-1424-8},
	abstract = {The ‘Tianjic’ hybrid electronic chip combines neuroscience-oriented and computer-science-oriented approaches to artificial general intelligence, demonstrated by controlling an unmanned bicycle.},
	pages = {106--111},
	number = {7767},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Pei, Jing and Deng, Lei and Song, Sen and Zhao, Mingguo and Zhang, Youhui and Wu, Shuang and Wang, Guanrui and Zou, Zhe and Wu, Zhenzhi and He, Wei and Chen, Feng and Deng, Ning and Wu, Si and Wang, Yu and Wu, Yujie and Yang, Zheyu and Ma, Cheng and Li, Guoqi and Han, Wentao and Li, Huanglong and Wu, Huaqiang and Zhao, Rong and Xie, Yuan and Shi, Luping},
	urldate = {2019-12-05},
	date = {2019-08},
	langid = {english},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/F3MQK23L/Pei et al. - 2019 - Towards artificial general intelligence with hybri.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/PNRSE474/s41586-019-1424-8.html:text/html}
}

@article{wold_principal_1987,
	title = {Principal component analysis},
	volume = {2},
	issn = {0169-7439},
	url = {http://www.sciencedirect.com/science/article/pii/0169743987800849},
	doi = {10.1016/0169-7439(87)80084-9},
	series = {Proceedings of the Multivariate Statistical Workshop for Geologists and Geochemists},
	abstract = {Principal component analysis of a data matrix extracts the dominant patterns in the matrix in terms of a complementary set of score and loading plots. It is the responsibility of the data analyst to formulate the scientific issue at hand in terms of {PC} projections, {PLS} regressions, etc. Ask yourself, or the investigator, why the data matrix was collected, and for what purpose the experiments and measurements were made. Specify before the analysis what kinds of patterns you would expect and what you would find exciting. The results of the analysis depend on the scaling of the matrix, which therefore must be specified. Variance scaling, where each variable is scaled to unit variance, can be recommended for general use, provided that almost constant variables are left unscaled. Combining different types of variables warrants blockscaling. In the initial analysis, look for outliers and strong groupings in the plots, indicating that the data matrix perhaps should be “polished” or whether disjoint modeling is the proper course. For plotting purposes, two or three principal components are usually sufficient, but for modeling purposes the number of significant components should be properly determined, e.g. by cross-validation. Use the resulting principal components to guide your continued investigation or chemical experimentation, not as an end in itself.},
	pages = {37--52},
	number = {1},
	journaltitle = {Chemometrics and Intelligent Laboratory Systems},
	shortjournal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
	urldate = {2019-12-13},
	date = {1987-08-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:/home/danielsan/Zotero/storage/XIL5LSJI/Wold et al. - 1987 - Principal component analysis.pdf:application/pdf;ScienceDirect Snapshot:/home/danielsan/Zotero/storage/6I2JP7CY/0169743987800849.html:text/html}
}

@article{oizumi_phenomenology_2014,
	title = {From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0},
	volume = {10},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1003588},
	doi = {10.1371/journal.pcbi.1003588},
	shorttitle = {From the Phenomenology to the Mechanisms of Consciousness},
	abstract = {This paper presents Integrated Information Theory ({IIT}) of consciousness 3.0, which incorporates several advances over previous formulations. {IIT} starts from phenomenological axioms: information says that each experience is specific – it is what it is by how it differs from alternative experiences; integration says that it is unified – irreducible to noninterdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as ‘‘differences that make a difference’’ within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, {IIT} arrives at an identity: an experience is a maximally irreducible conceptual structure ({MICS}, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a complex. According to {IIT}, a {MICS} specifies the quality of an experience and integrated information {WMax} its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated {MICS}; a complex can generate a {MICS} even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true ‘‘zombies’’ – unconscious feed-forward systems that are functionally equivalent to conscious complexes.},
	pages = {e1003588},
	number = {5},
	journaltitle = {{PLoS} Computational Biology},
	author = {Oizumi, Masafumi and Albantakis, Larissa and Tononi, Giulio},
	editor = {Sporns, Olaf},
	urldate = {2020-01-09},
	date = {2014-05-08},
	langid = {english},
	file = {Oizumi et al. - 2014 - From the Phenomenology to the Mechanisms of Consci.pdf:/home/danielsan/Zotero/storage/G7EZSMYL/Oizumi et al. - 2014 - From the Phenomenology to the Mechanisms of Consci.pdf:application/pdf}
}

@article{oizumi_measuring_2016,
	title = {Measuring Integrated Information from the Decoding Perspective},
	volume = {12},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1004654},
	doi = {10.1371/journal.pcbi.1004654},
	pages = {e1004654},
	number = {1},
	journaltitle = {{PLOS} Computational Biology},
	author = {Oizumi, Masafumi and Amari, Shun-ichi and Yanagawa, Toru and Fujii, Naotaka and Tsuchiya, Naotsugu},
	editor = {Polani, Daniel},
	urldate = {2020-01-09},
	date = {2016-01-21},
	langid = {english},
	file = {Oizumi et al. - 2016 - Measuring Integrated Information from the Decoding.pdf:/home/danielsan/Zotero/storage/I3NC2YXQ/Oizumi et al. - 2016 - Measuring Integrated Information from the Decoding.pdf:application/pdf}
}

@article{tononi_integrated_2016,
	title = {Integrated information theory: from consciousness to its physical substrate},
	volume = {17},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn.2016.44},
	doi = {10.1038/nrn.2016.44},
	shorttitle = {Integrated information theory},
	abstract = {In this Opinion article, we discuss how integrated information theory accounts for several aspects of the relationship between consciousness and the brain. Integrated information theory starts from the essential properties of phenomenal experience, from which it derives the requirements for the physical substrate of consciousness. It argues that the physical substrate of consciousness must be a maximum of intrinsic cause–effect power and provides a means to determine, in principle, the quality and quantity of experience. The theory leads to some counterintuitive predictions and can be used to develop new tools for assessing consciousness in non-communicative patients.},
	pages = {450--461},
	number = {7},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Tononi, Giulio and Boly, Melanie and Massimini, Marcello and Koch, Christof},
	urldate = {2020-01-09},
	date = {2016-07},
	langid = {english},
	file = {Tononi et al. - 2016 - Integrated information theory from consciousness .pdf:/home/danielsan/Zotero/storage/X2JX7JHQ/Tononi et al. - 2016 - Integrated information theory from consciousness .pdf:application/pdf}
}

@article{schossau_information-theoretic_2016,
	title = {Information-Theoretic Neuro-Correlates Boost Evolution of Cognitive Systems},
	volume = {18},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/18/1/6},
	doi = {10.3390/e18010006},
	abstract = {Genetic Algorithms ({GA}) are a powerful set of tools for search and optimization that mimic the process of natural selection, and have been used successfully in a wide variety of problems, including evolving neural networks to solve cognitive tasks. Despite their success, {GAs} sometimes fail to locate the highest peaks of the fitness landscape, in particular if the landscape is rugged and contains multiple peaks. Reaching distant and higher peaks is difficult because valleys need to be crossed, in a process that (at least temporarily) runs against the fitness maximization objective. Here we propose and test a number of information-theoretic (as well as network-based) measures that can be used in conjunction with a fitness maximization objective (so-called “neuro-correlates”) to evolve neural controllers for two widely different tasks: a behavioral task that requires information integration, and a cognitive task that requires memory and logic. We find that judiciously chosen neuro-correlates can significantly aid {GAs} to find the highest peaks.},
	pages = {6},
	number = {1},
	journaltitle = {Entropy},
	author = {Schossau, Jory and Adami, Christoph and Hintze, Arend},
	urldate = {2020-01-09},
	date = {2016-01},
	langid = {english},
	keywords = {genetic algorithm, evolution, information theory, markov brain, neuro-correlate},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/ZEU7NIE2/Schossau et al. - 2016 - Information-Theoretic Neuro-Correlates Boost Evolu.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/R9DYNBYT/htm.html:text/html}
}

@article{albantakis_evolution_2014-1,
	title = {Evolution of Integrated Causal Structures in Animats Exposed to Environments of Increasing Complexity},
	volume = {10},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1003966},
	doi = {10.1371/journal.pcbi.1003966},
	abstract = {Natural selection favors the evolution of brains that can capture fitness-relevant features of the environment’s causal structure. We investigated the evolution of small, adaptive logic-gate networks (‘‘animats’’) in task environments where falling blocks of different sizes have to be caught or avoided in a ‘Tetris-like’ game. Solving these tasks requires the integration of sensor inputs and memory. Evolved networks were evaluated using measures of information integration, including the number of evolved concepts and the total amount of integrated conceptual information. The results show that, over the course of the animats’ adaptation, i) the number of concepts grows; ii) integrated conceptual information increases; iii) this increase depends on the complexity of the environment, especially on the requirement for sequential memory. These results suggest that the need to capture the causal structure of a rich environment, given limited sensors and internal mechanisms, is an important driving force for organisms to develop highly integrated networks (‘‘brains’’) with many concepts, leading to an increase in their internal complexity.},
	pages = {e1003966},
	number = {12},
	journaltitle = {{PLoS} Computational Biology},
	author = {Albantakis, Larissa and Hintze, Arend and Koch, Christof and Adami, Christoph and Tononi, Giulio},
	editor = {Polani, Daniel},
	urldate = {2020-01-09},
	date = {2014-12-18},
	langid = {english},
	file = {Albantakis et al. - 2014 - Evolution of Integrated Causal Structures in Anima.pdf:/home/danielsan/Zotero/storage/RNBRWYDZ/Albantakis et al. - 2014 - Evolution of Integrated Causal Structures in Anima.pdf:application/pdf}
}

@article{edlund_integrated_2011,
	title = {Integrated Information Increases with Fitness in the Evolution of Animats},
	volume = {7},
	issn = {1553-7358},
	url = {http://dx.plos.org/10.1371/journal.pcbi.1002236},
	doi = {10.1371/journal.pcbi.1002236},
	abstract = {One of the hallmarks of biological organisms is their ability to integrate disparate information sources to optimize their behavior in complex environments. How this capability can be quantified and related to the functional complexity of an organism remains a challenging problem, in particular since organismal functional complexity is not well-defined. We present here several candidate measures that quantify information and integration, and study their dependence on fitness as an artificial agent (‘‘animat’’) evolves over thousands of generations to solve a navigation task in a simple, simulated environment. We compare the ability of these measures to predict high fitness with more conventional informationtheoretic processing measures. As the animat adapts by increasing its ‘‘fit’’ to the world, information integration and processing increase commensurately along the evolutionary line of descent. We suggest that the correlation of fitness with information integration and with processing measures implies that high fitness requires both information processing as well as integration, but that information integration may be a better measure when the task requires memory. A correlation of measures of information integration (but also information processing) and fitness strongly suggests that these measures reflect the functional complexity of the animat, and that such measures can be used to quantify functional complexity even in the absence of fitness data.},
	pages = {e1002236},
	number = {10},
	journaltitle = {{PLoS} Computational Biology},
	author = {Edlund, Jeffrey A. and Chaumont, Nicolas and Hintze, Arend and Koch, Christof and Tononi, Giulio and Adami, Christoph},
	editor = {Graham, Lyle J.},
	urldate = {2020-01-09},
	date = {2011-10-20},
	langid = {english},
	file = {Edlund et al. - 2011 - Integrated Information Increases with Fitness in t.pdf:/home/danielsan/Zotero/storage/GEJWVBVE/Edlund et al. - 2011 - Integrated Information Increases with Fitness in t.pdf:application/pdf}
}

@article{joshi_minimal_2013,
	title = {The Minimal Complexity of Adapting Agents Increases with Fitness},
	volume = {9},
	abstract = {What is the relationship between the complexity and the fitness of evolved organisms, whether natural or artificial? It has been asserted, primarily based on empirical data, that the complexity of plants and animals increases as their fitness within a particular environment increases via evolution by natural selection. We simulate the evolution of the brains of simple organisms living in a planar maze that they have to traverse as rapidly as possible. Their connectome evolves over 10,000s of generations. We evaluate their circuit complexity, using four information-theoretical measures, including one that emphasizes the extent to which any network is an irreducible entity. We find that their minimal complexity increases with their fitness.},
	pages = {10},
	number = {7},
	journaltitle = {{PLOS} Computational Biology},
	author = {Joshi, Nikhil J and Tononi, Giulio and Koch, Christof},
	date = {2013},
	langid = {english},
	file = {Joshi et al. - 2013 - The Minimal Complexity of Adapting Agents Increase.pdf:/home/danielsan/Zotero/storage/MWXPAFAF/Joshi et al. - 2013 - The Minimal Complexity of Adapting Agents Increase.pdf:application/pdf}
}

@article{ay_predictive_2008,
	title = {Predictive information and explorative behavior of autonomous robots},
	volume = {63},
	issn = {1434-6028, 1434-6036},
	url = {http://link.springer.com/10.1140/epjb/e2008-00175-0},
	doi = {10.1140/epjb/e2008-00175-0},
	abstract = {Measures of complexity are of immediate interest for the ﬁeld of autonomous robots both as a means to classify the behavior and as an objective function for the autonomous development of robot behavior. In the present paper we consider predictive information in sensor space as a measure for the behavioral complexity of a two-wheel embodied robot moving in a rectangular arena with several obstacles. The mutual information ({MI}) between past and future sensor values is found empirically to have a maximum for a behavior which is both explorative and sensitive to the environment. This makes predictive information a prospective candidate as an objective function for the autonomous development of such behaviors. We derive theoretical expressions for the {MI} in order to obtain an explicit update rule for the gradient ascent dynamics. Interestingly, in the case of a linear or linearized model of the sensorimotor dynamics the structure of the learning rule derived depends only on the dynamical properties while the value of the {MI} inﬂuences only the learning rate. In this way the problem of the prohibitively large sampling times for information theoretic measures can be circumvented. This result can be generalized and may help to derive explicit learning rules from complexity theoretic measures.},
	pages = {329--339},
	number = {3},
	journaltitle = {The European Physical Journal B},
	author = {Ay, N. and Bertschinger, N. and Der, R. and Güttler, F. and Olbrich, E.},
	urldate = {2020-01-09},
	date = {2008-06},
	langid = {english},
	file = {Ay et al. - 2008 - Predictive information and explorative behavior of.pdf:/home/danielsan/Zotero/storage/YPWMAP67/Ay et al. - 2008 - Predictive information and explorative behavior of.pdf:application/pdf}
}

@article{mayner_pyphi_2018,
	title = {{PyPhi}: A toolbox for integrated information theory},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006343},
	doi = {10.1371/journal.pcbi.1006343},
	shorttitle = {{PyPhi}},
	abstract = {Integrated information theory provides a mathematical framework to fully characterize the cause-effect structure of a physical system. Here, we introduce {PyPhi}, a Python software package that implements this framework for causal analysis and unfolds the full cause-effect structure of discrete dynamical systems of binary elements. The software allows users to easily study these structures, serves as an up-to-date reference implementation of the formalisms of integrated information theory, and has been applied in research on complexity, emergence, and certain biological questions. We first provide an overview of the main algorithm and demonstrate {PyPhi}’s functionality in the course of analyzing an example system, and then describe details of the algorithm’s design and implementation. {PyPhi} can be installed with Python’s package manager via the command ‘pip install pyphi’ on Linux and {macOS} systems equipped with Python 3.4 or higher. {PyPhi} is open-source and licensed under the {GPLv}3; the source code is hosted on {GitHub} at https://github.com/wmayner/pyphi. Comprehensive and continually-updated documentation is available at https://pyphi.readthedocs.io. The pyphi-users mailing list can be joined at https://groups.google.com/forum/\#!forum/pyphi-users. A web-based graphical interface to the software is available at http://integratedinformationtheory.org/calculate.html.},
	pages = {e1006343},
	number = {7},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Mayner, William G. P. and Marshall, William and Albantakis, Larissa and Findlay, Graham and Marchman, Robert and Tononi, Giulio},
	urldate = {2020-01-09},
	date = {2018-07-26},
	langid = {english},
	keywords = {Algorithms, Calculus, Dynamical systems, Information theory, Optimization, Probability distribution, Software design, Source code},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/UGGL9VAZ/Mayner et al. - 2018 - PyPhi A toolbox for integrated information theory.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/65HRLK35/article.html:text/html}
}

@inproceedings{schuman_evolutionary_2016,
	title = {An evolutionary optimization framework for neural networks and neuromorphic architectures},
	doi = {10.1109/IJCNN.2016.7727192},
	abstract = {As new neural network and neuromorphic architectures are being developed, new training methods that operate within the constraints of the new architectures are required. Evolutionary optimization ({EO}) is a convenient training method for new architectures. In this work, we review a spiking neural network architecture and a neuromorphic architecture, and we describe an {EO} training framework for these architectures. We present the results of this training framework on four classification data sets and compare those results to other neural network and neuromorphic implementations. We also discuss how this {EO} framework may be extended to other architectures.},
	eventtitle = {2016 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {145--154},
	booktitle = {2016 International Joint Conference on Neural Networks ({IJCNN})},
	author = {Schuman, Catherine D. and Plank, James S. and Disney, Adam and Reynolds, John},
	date = {2016-07},
	note = {{ISSN}: 2161-4407},
	keywords = {Computer architecture, Neurons, Hardware, learning (artificial intelligence), Neuromorphics, evolutionary computation, Optimization, Artificial neural networks, {EO} training framework, evolutionary optimization framework, neural net architecture, neuromorphic architecture, optimisation, spiking neural network architecture, Training},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/U5TUD7RY/7727192.html:text/html;IEEE Xplore Full Text PDF:/home/danielsan/Zotero/storage/A7BX3IB8/Schuman et al. - 2016 - An evolutionary optimization framework for neural .pdf:application/pdf}
}

@online{noauthor_parallel_nodate,
	title = {Parallel evolutionary optimization for neuromorphic network training {\textbar} Proceedings of the Workshop on Machine Learning in High Performance Computing Environments},
	url = {https://dl.acm.org/doi/abs/10.5555/3018874.3018879},
	urldate = {2020-01-09},
	file = {Snapshot:/home/danielsan/Zotero/storage/45ZLVKEI/3018874.html:text/html}
}

@inproceedings{schuman_parallel_2016,
	location = {Salt Lake City, {UT}, {USA}},
	title = {Parallel Evolutionary Optimization for Neuromorphic Network Training},
	isbn = {978-1-5090-3882-4},
	url = {http://ieeexplore.ieee.org/document/7835813/},
	doi = {10.1109/MLHPC.2016.008},
	abstract = {One of the key impediments to the success of current neuromorphic computing architectures is the issue of how best to program them. Evolutionary optimization ({EO}) is one promising programming technique; in particular, its wide applicability makes it especially attractive for neuromorphic architectures, which can have many different characteristics. In this paper, we explore different facets of {EO} on a spiking neuromorphic computing model called {DANNA}. We focus on the performance of {EO} in the design of our {DANNA} simulator, and on how to structure {EO} on both multicore and massively parallel computing systems. We evaluate how our parallel methods impact the performance of {EO} on Titan, the U.S.’s largest open science supercomputer, and {BOB}, a Beowulf-style cluster of Raspberry Pi’s. We also focus on how to improve the {EO} by evaluating commonality in higher performing neural networks, and present the result of a study that evaluates the {EO} performed by Titan.},
	eventtitle = {2016 2nd Workshop on Machine Learning in {HPC} Environments ({MLHPC})},
	pages = {36--46},
	booktitle = {2016 2nd Workshop on Machine Learning in {HPC} Environments ({MLHPC})},
	publisher = {{IEEE}},
	author = {Schuman, Catherine D. and Disney, Adam and Singh, Susheela P. and Bruer, Grant and Mitchell, J. Parker and Klibisz, Aleksander and Plank, James S.},
	urldate = {2020-01-09},
	date = {2016-11},
	langid = {english},
	file = {Schuman et al. - 2016 - Parallel Evolutionary Optimization for Neuromorphi.pdf:/home/danielsan/Zotero/storage/PIBEG4C9/Schuman et al. - 2016 - Parallel Evolutionary Optimization for Neuromorphi.pdf:application/pdf}
}

@inproceedings{schuman_island_2019,
	location = {Prague, Czech Republic},
	title = {Island model for parallel evolutionary optimization of spiking neuromorphic computing},
	isbn = {978-1-4503-6748-6},
	url = {http://dl.acm.org/citation.cfm?doid=3319619.3322016},
	doi = {10.1145/3319619.3322016},
	abstract = {Parallel genetic algorithms ({PGAs}) can be used to accelerate optimization by exploiting large-scale computational resources. In this work, we describe a {PGA} framework for evolving spiking neural networks ({SNNs}) for neuromorphic hardware implementation. The {PGA} framework is based on an islands model with migration. We show that using this framework, better {SNNs} for neuromorphic systems can be evolved faster.},
	eventtitle = {the Genetic and Evolutionary Computation Conference Companion},
	pages = {306--307},
	booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion on   - {GECCO} '19},
	publisher = {{ACM} Press},
	author = {Schuman, Catherine D. and Plank, James S. and Patton, Robert M. and Potok, Thomas E.},
	urldate = {2020-01-09},
	date = {2019},
	langid = {english},
	file = {Schuman et al. - 2019 - Island model for parallel evolutionary optimizatio.pdf:/home/danielsan/Zotero/storage/2LYHE4UP/Schuman et al. - 2019 - Island model for parallel evolutionary optimizatio.pdf:application/pdf}
}

@online{noauthor_spiking_nodate,
	title = {{SPIKING} {NEURAL} {NETWORKS} {\textbar} International Journal of Neural Systems},
	url = {https://www.worldscientific.com/doi/pdf/10.1142/S0129065709002002},
	urldate = {2020-01-09},
	file = {SPIKING NEURAL NETWORKS | International Journal of Neural Systems:/home/danielsan/Zotero/storage/476CXX85/S0129065709002002.html:text/html}
}

@incollection{rozenberg_computing_2012,
	location = {Berlin, Heidelberg},
	title = {Computing with Spiking Neuron Networks},
	isbn = {978-3-540-92909-3 978-3-540-92910-9},
	url = {http://link.springer.com/10.1007/978-3-540-92910-9_10},
	abstract = {Spiking Neuron Networks ({SNNs}) are often referred to as the third generation of neural networks. Highly inspired by natural computing in the brain and recent advances in neurosciences, they derive their strength and interest from an accurate modeling of synaptic interactions between neurons, taking into account the time of spike ﬁring. {SNNs} overcome the computational power of neural networks made of threshold or sigmoidal units. Based on dynamic event-driven processing, they open up new horizons for developing models with an exponential capacity to memorize and a strong ability to do fast adaptation. Today, the main challenge is to discover efﬁcient learning rules that might take advantage of the speciﬁc features of {SNNs} while keeping the nice properties (general-purpose, easy-to-use, available simulators, etc.) of traditional connectionist models. This chapter relates the history of the ‘‘spiking neuron’’ in {\textgreater} Sect. 1 and summarizes the most currently-in-use models of neurons and synaptic plasticity in {\textgreater} Sect. 2. The computational power of {SNNs} is addressed in {\textgreater} Sect. 3 and the problem of learning in networks of spiking neurons is tackled in {\textgreater} Sect. 4, with insights into the tracks currently explored for solving it. Finally, {\textgreater} Sect. 5 discusses application domains, implementation issues and proposes several simulation frameworks.},
	pages = {335--376},
	booktitle = {Handbook of Natural Computing},
	publisher = {Springer Berlin Heidelberg},
	author = {Paugam-Moisy, Hélène and Bohte, Sander},
	editor = {Rozenberg, Grzegorz and Bäck, Thomas and Kok, Joost N.},
	urldate = {2020-01-09},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-540-92910-9_10},
	file = {Paugam-Moisy and Bohte - 2012 - Computing with Spiking Neuron Networks.pdf:/home/danielsan/Zotero/storage/4CG9RZCX/Paugam-Moisy and Bohte - 2012 - Computing with Spiking Neuron Networks.pdf:application/pdf}
}

@article{ghosh-dastidar_improved_2007,
	title = {Improved spiking neural networks for {EEG} classification and epilepsy and seizure detection},
	volume = {14},
	issn = {18758835, 10692509},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/ICA-2007-14301},
	doi = {10.3233/ICA-2007-14301},
	abstract = {The goal of this research is to develop an efﬁcient {SNN} model for epilepsy and epileptic seizure detection using electroencephalograms ({EEGs}), a complicated pattern recognition problem. Three training algorithms are investigated: {SpikeProp} (using both incremental and batch processing), {QuickProp}, and {RProp}. Since the epilepsy and epileptic seizure detection problem requires a large training dataset the efﬁcacy of these algorithms is investigated by ﬁrst applying them to the {XOR} and Fisher iris benchmark problems. Three measures of performance are investigated: number of convergence epochs, computational efﬁciency, and classiﬁcation accuracy. Extensive parametric analysis is performed to identify heuristic rules and optimum parameter values that increase the computational efﬁciency and classiﬁcation accuracy. The result is a remarkable increase in computational efﬁciency. For the {XOR} problem, the computational efﬁciency of {SpikeProp}, {QuickProp}, and {RProp} is increased by a factor of 588, 82, and 75, respectively, compared with the results reported in the literature. {EEGs} from three different subject groups are analyzed: (a) healthy subjects, (b) epileptic subjects during a seizure-free interval, and (c) epileptic subjects during a seizure. It is concluded that {RProp} is the best training algorithm because it has the highest classiﬁcation accuracy among all training algorithms specially for large size training datasets with about the same computational efﬁciency provided by {SpikeProp}. The {SNN} model for {EEG} classiﬁcation and epilepsy and seizure detection uses {RProp} as training algorithm. This model yields a high classiﬁcation accuracy of 92.5\%.},
	pages = {187--212},
	number = {3},
	journaltitle = {Integrated Computer-Aided Engineering},
	author = {Ghosh-Dastidar, Samanwoy and Adeli, Hojjat},
	urldate = {2020-01-09},
	date = {2007-05-13},
	langid = {english},
	file = {Ghosh-Dastidar and Adeli - 2007 - Improved spiking neural networks for EEG classific.pdf:/home/danielsan/Zotero/storage/B7BWAN7U/Ghosh-Dastidar and Adeli - 2007 - Improved spiking neural networks for EEG classific.pdf:application/pdf}
}

@article{sloss_2019_2019,
	title = {2019 Evolutionary Algorithms Review},
	url = {http://arxiv.org/abs/1906.08870},
	abstract = {Evolutionary algorithm research and applications began over 50 years ago. Like other artiﬁcial intelligence techniques, evolutionary algorithms will likely see increased use and development due to the increased availability of computation, more robust and available open source software libraries, and the increasing demand for artiﬁcial intelligence techniques. As these techniques become more adopted and capable, it is the right time to take a perspective of their ability to integrate into society and the human processes they intend to augment. In this review, we explore a new taxonomy of evolutionary algorithms and resulting classiﬁcations that look at ﬁve main areas: the ability to manage the control of the environment with limiters, the ability to explain and repeat the search process, the ability to understand input and output causality within a solution, the ability to manage algorithm bias due to data or user design, and lastly, the ability to add corrective measures. These areas are motivated by today’s pressures on industry to conform to both societies concerns and new government regulatory rules. As many reviews of evolutionary algorithms exist, after motivating this new taxonomy, we brieﬂy classify a broad range of algorithms and identify areas of future research.},
	journaltitle = {{arXiv}:1906.08870 [cs]},
	author = {Sloss, Andrew N. and Gustafson, Steven},
	urldate = {2020-01-12},
	date = {2019-06-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1906.08870},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
	file = {Sloss and Gustafson - 2019 - 2019 Evolutionary Algorithms Review.pdf:/home/danielsan/Zotero/storage/KSH6FN6M/Sloss and Gustafson - 2019 - 2019 Evolutionary Algorithms Review.pdf:application/pdf}
}

@book{wilson_animat_1991,
	title = {The Animat Path to {AI}},
	abstract = {A research methodology is proposed for understanding intelligence through simulation of artificial animals ("animats") in progressively more challenging environments while retaining characteristics of holism, pragmatism, perception, categorization, and adaptation that are often underrepresented in standard {AI} approaches to intelligence. It is suggested that basic elements of the methodology should include a theory/taxonomy of environments by which they can be ordered in difficulty---one is offered---and a theory of animat efficiency. It is also suggested that the methodology offers a new approach to the problem of perception.},
	author = {Wilson, S. W.},
	date = {1991},
	file = {Citeseer - Full Text PDF:/home/danielsan/Zotero/storage/R8GMQVLP/Wilson - 1991 - The Animat Path to AI.pdf:application/pdf;Citeseer - Snapshot:/home/danielsan/Zotero/storage/K3WFBE2L/summary.html:text/html}
}

@inproceedings{franklin_is_1997,
	location = {Berlin, Heidelberg},
	title = {Is It an agent, or just a program?: A taxonomy for autonomous agents},
	isbn = {978-3-540-68057-4},
	doi = {10.1007/BFb0013570},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Is It an agent, or just a program?},
	abstract = {The advent of software agents gave rise to much discussion of just what such an agent is, and of how they differ from programs in general. Here we propose a formal definition of an autonomous agent which clearly distinguishes a software agent from just any program. We also offer the beginnings of a natural kinds taxonomy of autonomous agents, and discuss possibilities for further classification. Finally, we discuss subagents and multiagent systems.},
	pages = {21--35},
	booktitle = {Intelligent Agents {III} Agent Theories, Architectures, and Languages},
	publisher = {Springer},
	author = {Franklin, Stan and Graesser, Art},
	editor = {Müller, Jörg P. and Wooldridge, Michael J. and Jennings, Nicholas R.},
	date = {1997},
	langid = {english},
	keywords = {Autonomous Agent, Intelligent Agent, Mobile Agent, Multiagent System, Natural Kind},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/PKZ8CHDQ/Franklin and Graesser - 1997 - Is It an agent, or just a program A taxonomy for.pdf:application/pdf}
}

@article{floreano_automatic_1994,
	title = {Automatic Creation of an Autonomous Agent: Genetic Evolution of a Neural Network Driven Robot},
	url = {http://hdl.handle.net/20.500.11850/82611},
	doi = {10.3929/ethz-a-010111549},
	shorttitle = {Automatic Creation of an Autonomous Agent},
	abstract = {The paper describes the results of the evolutionary development of a real, neural-network driven mobile robot. The evolutionary approach to the development of neural controllers for autonomous agents has been successfully used by many researchers, but most -if not all- studies have been carried out with computer simulations. Instead, in this research the whole evolutionary process takes places entirely on a real robot without human intervention. Although the experiments described here tackle a simple task of navigation and obstacle avoidance, we show a number of emergent phenomena that are characteristic of autonomous agents. The neural controllers of the evolved best individuals display a full exploitation of non-linear and recurrent connections that make them more e cient than analogous man-designed agents. In order to fully understand and describe the robot behavior, we have also employed quantitative ethological tools 13], and showed that the adaptation dynamics conform to predictions made for animals.},
	journaltitle = {{ETH} Zurich},
	author = {Floreano, Dario and Mondada, Francesco},
	urldate = {2020-01-12},
	date = {1994},
	langid = {english},
	file = {Floreano and Mondada - 1994 - Automatic Creation of an Autonomous Agent Genetic.pdf:/home/danielsan/Zotero/storage/FR5PYZRY/Floreano and Mondada - 1994 - Automatic Creation of an Autonomous Agent Genetic.pdf:application/pdf}
}

@incollection{turing_computing_2009,
	location = {Dordrecht},
	title = {Computing Machinery and Intelligence},
	isbn = {978-1-4020-6710-5},
	url = {https://doi.org/10.1007/978-1-4020-6710-5_3},
	abstract = {I propose to consider the question, “Can machines think?”♣ This should begin with definitions of the meaning of the terms “machine” and “think”. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words “machine” and “think” are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, “Can machines think?” is to be sought in a statistical survey such as a Gallup poll.},
	pages = {23--65},
	booktitle = {Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer},
	publisher = {Springer Netherlands},
	author = {Turing, Alan M.},
	editor = {Epstein, Robert and Roberts, Gary and Beber, Grace},
	urldate = {2020-01-12},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-1-4020-6710-5_3},
	keywords = {Computing Machinery, Digital Computer, Performance Capacity, Real Robot, Turing Machine},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/8C5EYRXW/Turing - 2009 - Computing Machinery and Intelligence.pdf:application/pdf}
}

@article{haun_why_2019,
	title = {Why Does Space Feel the Way it Does? Towards a Principled Account of Spatial Experience},
	volume = {21},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/21/12/1160},
	doi = {10.3390/e21121160},
	shorttitle = {Why Does Space Feel the Way it Does?},
	abstract = {There must be a reason why an experience feels the way it does. A good place to begin addressing this question is spatial experience, because it may be more penetrable by introspection than other qualities of consciousness such as color or pain. Moreover, much of experience is spatial, from that of our body to the visual world, which appears as if painted on an extended canvas in front of our eyes. Because it is \&lsquo;right there\&rsquo;, we usually take space for granted and overlook its qualitative properties. However, we should realize that a great number of phenomenal distinctions and relations are required for the canvas of space to feel \&lsquo;extended\&rsquo;. Here we argue that, to be experienced as extended, the canvas of space must be composed of countless spots, here and there, small and large, and these spots must be related to each other in a characteristic manner through connection, fusion, and inclusion. Other aspects of the structure of spatial experience follow from extendedness: every spot can be experienced as enclosing a particular region, with its particular location, size, boundary, and distance from other spots. We then propose an account of the phenomenal properties of spatial experiences based on integrated information theory ({IIT}). The theory provides a principled approach for characterizing both the quantity and quality of experience by unfolding the cause-effect structure of a physical substrate. Specifically, we show that a simple simulated substrate of units connected in a grid-like manner yields a cause-effect structure whose properties can account for the main properties of spatial experience. These results uphold the hypothesis that our experience of space is supported by brain areas whose units are linked by a grid-like connectivity. They also predict that changes in connectivity, even in the absence of changes in activity, should lead to a warping of experienced space. To the extent that this approach provides an initial account of phenomenal space, it may also serve as a starting point for investigating other aspects of the quality of experience and their physical correspondents.},
	pages = {1160},
	number = {12},
	journaltitle = {Entropy},
	author = {Haun, Andrew and Tononi, Giulio},
	urldate = {2020-01-12},
	date = {2019-12},
	langid = {english},
	keywords = {causal structure, consciousness, grid networks, integrated information theory, phenomenology, qualia},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/DWY4MN6S/Haun and Tononi - 2019 - Why Does Space Feel the Way it Does Towards a Pri.pdf:application/pdf;Snapshot:/home/danielsan/Zotero/storage/MV4PMTPP/1160.html:text/html}
}

@article{haenlein_brief_2019,
	title = {A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence},
	volume = {61},
	issn = {0008-1256},
	url = {https://doi.org/10.1177/0008125619864925},
	doi = {10.1177/0008125619864925},
	shorttitle = {A Brief History of Artificial Intelligence},
	abstract = {This introduction to this special issue discusses artificial intelligence ({AI}), commonly defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.” It summarizes seven articles published in this special issue that present a wide variety of perspectives on {AI}, authored by several of the world’s leading experts and specialists in {AI}. It concludes by offering a comprehensive outlook on the future of {AI}, drawing on micro-, meso-, and macro-perspectives.},
	pages = {5--14},
	number = {4},
	journaltitle = {California Management Review},
	shortjournal = {California Management Review},
	author = {Haenlein, Michael and Kaplan, Andreas},
	urldate = {2020-01-13},
	date = {2019-08-01},
	langid = {english},
	keywords = {artificial intelligence, big data, machine-based learning, regulation, strategy},
	file = {SAGE PDF Full Text:/home/danielsan/Zotero/storage/QFVUB69E/Haenlein and Kaplan - 2019 - A Brief History of Artificial Intelligence On the.pdf:application/pdf}
}

@article{cowan_discussion_1990,
	title = {Discussion: {McCulloch}-Pitts and related neural nets from 1943 to 1989},
	volume = {52},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02459569},
	doi = {10.1007/BF02459569},
	shorttitle = {Discussion},
	abstract = {The {McCulloch}-Pitts paper “A Logical Calculus of the Ideas Immanent in Nervous Activity” was published in {theBulletin} of Mathematical Biophysics in 1943, a decade before the work of Hodgkin, Huxley, Katz and Eccles. The {McCulloch}-Pitts neuron is an extremely simplified representation of neural properties, based simply on the existence of a threshold for the activation of an action potential.},
	pages = {73--97},
	number = {1},
	journaltitle = {Bulletin of Mathematical Biology},
	shortjournal = {Bltn Mathcal Biology},
	author = {Cowan, Jack D.},
	urldate = {2020-01-13},
	date = {1990-01-01},
	langid = {english},
	keywords = {Associative Memory, Logical Function, Motor Unit, Receptive Field, Synaptic Weight},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/M2AVHSTU/Cowan - 1990 - Discussion McCulloch-Pitts and related neural net.pdf:application/pdf}
}

@article{burkitt_review_2006,
	title = {A Review of the Integrate-and-fire Neuron Model: I. Homogeneous Synaptic Input},
	volume = {95},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/s00422-006-0068-6},
	doi = {10.1007/s00422-006-0068-6},
	shorttitle = {A Review of the Integrate-and-fire Neuron Model},
	abstract = {The integrate-and-fire neuron model is one of the most widely used models for analyzing the behavior of neural systems. It describes the membrane potential of a neuron in terms of the synaptic inputs and the injected current that it receives. An action potential (spike) is generated when the membrane potential reaches a threshold, but the actual changes associated with the membrane voltage and conductances driving the action potential do not form part of the model. The synaptic inputs to the neuron are considered to be stochastic and are described as a temporally homogeneous Poisson process. Methods and results for both current synapses and conductance synapses are examined in the diffusion approximation, where the individual contributions to the postsynaptic potential are small. The focus of this review is upon the mathematical techniques that give the time distribution of output spikes, namely stochastic differential equations and the Fokker–Planck equation. The integrate-and-fire neuron model has become established as a canonical model for the description of spiking neurons because it is capable of being analyzed mathematically while at the same time being sufficiently complex to capture many of the essential features of neural processing. A number of variations of the model are discussed, together with the relationship with the Hodgkin–Huxley neuron model and the comparison with electrophysiological data. A brief overview is given of two issues in neural information processing that the integrate-and-fire neuron model has contributed to – the irregular nature of spiking in cortical neurons and neural gain modulation.},
	pages = {1--19},
	number = {1},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol Cybern},
	author = {Burkitt, A. N.},
	urldate = {2020-01-13},
	date = {2006-07-01},
	langid = {english},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/DRGJW4DA/Burkitt - 2006 - A Review of the Integrate-and-fire Neuron Model I.pdf:application/pdf}
}

@inproceedings{holt_11_2016,
	title = {1.1 Moore's law: A path going forward},
	doi = {10.1109/ISSCC.2016.7417888},
	shorttitle = {1.1 Moore's law},
	abstract = {Semiconductors continue to be the foundation for computing and communications solutions, the basis of the Internet of Everthing, and the primary driver in the future of electronics applications. Moore's Law has led to evermore-powerful smart phones, tablets, personal computers, and data centers. It has enabled computing to become a seamless and powerful force in our homes, offices, cars, factories, and much more. Much has been written about the end of Moore's Law. More recently, speculation has focused on the economic end of Moore's Law. Gordon Moore initially projected 10 years of visibility. [35] Over fifty years later, the Moore's Law horizon remains around 10 years. Moore's Law was never guaranteed. It has thrived and will continue to do so as the result of continuous innovation, rigorous planning, and technology execution. Even though it is getting more expensive to build wafers, improvements in density can provide real cost reduction at the most fundamental level, and this economic benefit drives the ability to continue investing in Moore's Law. Innovations have driven Moore's Law through numerous technological transitions and will continue to power us into the future of {CMOS} and beyond. As long as there is a cost benefit and rich options for future innovations there is no reason to predict an early end!},
	eventtitle = {2016 {IEEE} International Solid-State Circuits Conference ({ISSCC})},
	pages = {8--13},
	booktitle = {2016 {IEEE} International Solid-State Circuits Conference ({ISSCC})},
	author = {Holt, William M.},
	date = {2016-01},
	note = {{ISSN}: 2376-8606},
	keywords = {Bandwidth, {CMOS} future and beyond, {CMOS} integrated circuits, {CMOS} technology, data centers, electronic engineering computing, electronics applications, Gordon Moore, Internet of Everthing, Moores law, personal computers, semiconductor technology, Silicon, smart phones, tablets, Three-dimensional displays},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/LQ6RTSS7/7417888.html:text/html}
}

@online{noauthor_is_nodate,
	title = {Is Moore’s Law Slowing Down? What’s Next?},
	url = {https://www.computer.org/csdl/magazine/mi/2017/04/mmi2017040004/13rRUxBa5gP},
	urldate = {2020-01-13},
	file = {Is Moore’s Law Slowing Down? What’s Next?:/home/danielsan/Zotero/storage/B4D5TDLJ/13rRUxBa5gP.html:text/html}
}

@article{schuman_survey_2017,
	title = {A Survey of Neuromorphic Computing and Neural Networks in Hardware},
	url = {http://arxiv.org/abs/1705.06963},
	abstract = {Neuromorphic computing has come to refer to a variety of brain-inspired computers, devices, and models that contrast the pervasive von Neumann computer architecture. This biologically inspired approach has created highly connected synthetic neurons and synapses that can be used to model neuroscience theories as well as solve challenging machine learning problems. The promise of the technology is to create a brain-like ability to learn and adapt, but the technical challenges are significant, starting with an accurate neuroscience model of how the brain works, to finding materials and engineering breakthroughs to build devices to support these models, to creating a programming framework so the systems can learn, to creating applications with brain-like capabilities. In this work, we provide a comprehensive survey of the research and motivations for neuromorphic computing over its history. We begin with a 35-year review of the motivations and drivers of neuromorphic computing, then look at the major research areas of the field, which we define as neuro-inspired models, algorithms and learning approaches, hardware and devices, supporting systems, and finally applications. We conclude with a broad discussion on the major research topics that need to be addressed in the coming years to see the promise of neuromorphic computing fulfilled. The goals of this work are to provide an exhaustive review of the research conducted in neuromorphic computing since the inception of the term, and to motivate further work by illuminating gaps in the field where new research is needed.},
	journaltitle = {{arXiv}:1705.06963 [cs]},
	author = {Schuman, Catherine D. and Potok, Thomas E. and Patton, Robert M. and Birdwell, J. Douglas and Dean, Mark E. and Rose, Garrett S. and Plank, James S.},
	urldate = {2020-01-13},
	date = {2017-05-19},
	eprinttype = {arxiv},
	eprint = {1705.06963},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/danielsan/Zotero/storage/BKYL7USS/Schuman et al. - 2017 - A Survey of Neuromorphic Computing and Neural Netw.pdf:application/pdf;arXiv.org Snapshot:/home/danielsan/Zotero/storage/FTWRVVVP/1705.html:text/html}
}

@book{eiben_introduction_2015,
	location = {Heidelberg},
	edition = {2. ed},
	title = {Introduction to evolutionary computing},
	isbn = {978-3-662-44873-1 978-3-662-44874-8},
	series = {Natural computing series},
	pagetotal = {287},
	publisher = {Springer},
	author = {Eiben, Agoston E. and Smith, James E.},
	date = {2015},
	langid = {english},
	note = {{OCLC}: 934627991},
	file = {Eiben and Smith - 2015 - Introduction to evolutionary computing.pdf:/home/danielsan/Zotero/storage/FQ4VHIBN/Eiben and Smith - 2015 - Introduction to evolutionary computing.pdf:application/pdf}
}

@book{trefzer_evolvable_2015,
	location = {Berlin Heidelberg},
	title = {Evolvable hardware: from practice to application},
	isbn = {978-3-662-44615-7 978-3-662-44616-4},
	series = {Natural computing series},
	shorttitle = {Evolvable hardware},
	pagetotal = {411},
	publisher = {Springer},
	author = {Trefzer, Martin Albrecht and Tyrrell, Andrew M.},
	date = {2015},
	langid = {english},
	file = {Trefzer and Tyrrell - 2015 - Evolvable hardware from practice to application.pdf:/home/danielsan/Zotero/storage/QITPJAQY/Trefzer and Tyrrell - 2015 - Evolvable hardware from practice to application.pdf:application/pdf}
}

@article{ghosh-dastidar_spiking_2009,
	title = {Spiking neural networks},
	volume = {19},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0129065709002002},
	doi = {10.1142/S0129065709002002},
	abstract = {Most current Artificial Neural Network ({ANN}) models are based on highly simplified brain dynamics. They have been used as powerful computational tools to solve complex pattern recognition, function estimation, and classification problems. {ANNs} have been evolving towards more powerful and more biologically realistic models. In the past decade, Spiking Neural Networks ({SNNs}) have been developed which comprise of spiking neurons. Information transfer in these neurons mimics the information transfer in biological neurons, i.e., via the precise timing of spikes or a sequence of spikes. To facilitate learning in such networks, new learning algorithms based on varying degrees of biological plausibility have also been developed recently. Addition of the temporal dimension for information encoding in {SNNs} yields new insight into the dynamics of the human brain and could result in compact representations of large neural networks. As such, {SNNs} have great potential for solving complicated time-dependent pattern recognition problems because of their inherent dynamic representation. This article presents a state-of-the-art review of the development of spiking neurons and {SNNs}, and provides insight into their evolution as the third generation neural networks.},
	pages = {295--308},
	number = {4},
	journaltitle = {International Journal of Neural Systems},
	shortjournal = {Int. J. Neur. Syst.},
	author = {Ghosh-Dastidar, Samanwoy and Adeli, Hojjat},
	urldate = {2020-01-13},
	date = {2009-08-01},
	file = {Snapshot:/home/danielsan/Zotero/storage/Q4EXUJGG/S0129065709002002.html:text/html;Submitted Version:/home/danielsan/Zotero/storage/L6AXNH8H/Ghosh-Dastidar and Adeli - 2009 - Spiking neural networks.pdf:application/pdf}
}

@article{cao_spiking_2015,
	title = {Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition},
	volume = {113},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-014-0788-3},
	doi = {10.1007/s11263-014-0788-3},
	abstract = {Deep-learning neural networks such as convolutional neural network ({CNN}) have shown great potential as a solution for difficult vision problems, such as object recognition. Spiking neural networks ({SNN})-based architectures have shown great potential as a solution for realizing ultra-low power consumption using spike-based neuromorphic hardware. This work describes a novel approach for converting a deep {CNN} into a {SNN} that enables mapping {CNN} to spike-based hardware architectures. Our approach first tailors the {CNN} architecture to fit the requirements of {SNN}, then trains the tailored {CNN} in the same way as one would with {CNN}, and finally applies the learned network weights to an {SNN} architecture derived from the tailored {CNN}. We evaluate the resulting {SNN} on publicly available Defense Advanced Research Projects Agency ({DARPA}) Neovision2 Tower and {CIFAR}-10 datasets and show similar object recognition accuracy as the original {CNN}. Our {SNN} implementation is amenable to direct mapping to spike-based neuromorphic hardware, such as the ones being developed under the {DARPA} {SyNAPSE} program. Our hardware mapping analysis suggests that {SNN} implementation on such spike-based hardware is two orders of magnitude more energy-efficient than the original {CNN} implementation on off-the-shelf {FPGA}-based hardware.},
	pages = {54--66},
	number = {1},
	journaltitle = {International Journal of Computer Vision},
	shortjournal = {Int J Comput Vis},
	author = {Cao, Yongqiang and Chen, Yang and Khosla, Deepak},
	urldate = {2020-01-13},
	date = {2015-05-01},
	langid = {english},
	keywords = {Machine learning, Convolutional neural networks, Deep learning, Neuromorphic circuits, Object recognition, Spiking neural networks},
	file = {Springer Full Text PDF:/home/danielsan/Zotero/storage/QSTIU58F/Cao et al. - 2015 - Spiking Deep Convolutional Neural Networks for Ene.pdf:application/pdf}
}

@article{lee_training_2016,
	title = {Training Deep Spiking Neural Networks Using Backpropagation},
	volume = {10},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2016.00508/full},
	doi = {10.3389/fnins.2016.00508},
	abstract = {Deep spiking neural networks ({SNNs}) hold the potential for improving the latency and energy efficiency of deep neural networks through data-driven event-based computation. However, training such networks is difficult due to the non-differentiable nature of spike events. In this paper, we introduce a novel technique, which treats the membrane potentials of spiking neurons as differentiable signals, where discontinuities at spike times are considered as noise. This enables an error backpropagation mechanism for deep {SNNs} that follows the same principles as in conventional deep networks, but works directly on spike signals and membrane potentials. Compared with previous methods relying on indirect training and conversion, our technique has the potential to capture the statistics of spikes more precisely. We evaluate the proposed framework on artificially generated events from the original {MNIST} handwritten digit benchmark, and also on the N-{MNIST} benchmark recorded with an event-based dynamic vision sensor, in which the proposed method reduces the error rate by a factor of more than three compared to the best previous {SNN}, and also achieves a higher accuracy than a conventional convolutional neural network ({CNN}) trained and tested on the same data. We demonstrate in the context of the {MNIST} task that thanks to their event-driven operation, deep {SNNs} (both fully connected and convolutional) trained with our method achieve accuracy equivalent with conventional neural networks. In the N-{MNIST} example, equivalent accuracy is achieved with about five times fewer computational operations.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Lee, Jun Haeng and Delbruck, Tobi and Pfeiffer, Michael},
	urldate = {2020-01-13},
	date = {2016},
	keywords = {backpropagation, Deep neural network, {DVS}, {MNIST}, N-{MNIST}, Neuromorphic, Spiking Neural network},
	file = {Full Text PDF:/home/danielsan/Zotero/storage/2NJ3W5DM/Lee et al. - 2016 - Training Deep Spiking Neural Networks Using Backpr.pdf:application/pdf}
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: A probabilistic model for information storage and organization in the brain},
	volume = {65},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/h0042519},
	shorttitle = {The perceptron},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {386--408},
	number = {6},
	journaltitle = {Psychological Review},
	author = {Rosenblatt, F.},
	date = {1958},
	keywords = {Brain, Cognition, Memory, Nervous System},
	file = {Snapshot:/home/danielsan/Zotero/storage/Y4K5GM89/1959-09865-001.html:text/html;Submitted Version:/home/danielsan/Zotero/storage/9PMQUQ3Q/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf:application/pdf}
}

@article{newell_perceptrons_1969,
	title = {Perceptrons. An Introduction to Computational Geometry. Marvin Minsky and Seymour Papert. M.I.T. Press, Cambridge, Mass., 1969. vi + 258 pp., illus. Cloth, \$12; paper, \$4.95},
	volume = {165},
	rights = {© 1969},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/165/3895/780},
	doi = {10.1126/science.165.3895.780},
	pages = {780--782},
	number = {3895},
	journaltitle = {Science},
	author = {Newell, Allen},
	urldate = {2020-01-14},
	date = {1969-08-22},
	langid = {english},
	file = {Snapshot:/home/danielsan/Zotero/storage/QFNZCKC8/780.html:text/html}
}

@book{minsky_perceptrons_2017,
	title = {Perceptrons: An Introduction to Computational Geometry},
	isbn = {978-0-262-53477-2},
	shorttitle = {Perceptrons},
	abstract = {The first systematic study of parallelism in computation by two pioneers in the field.Reissue of the 1988 Expanded Edition with a new foreword by Léon {BottouIn} 1969, ten years after the discovery of the perceptron—which showed that a machine could be taught to perform certain tasks using examples—Marvin Minsky and Seymour Papert published Perceptrons, their analysis of the computational capabilities of perceptrons for specific tasks. As Léon Bottou writes in his foreword to this edition, “Their rigorous work and brilliant technique does not make the perceptron look very good.” Perhaps as a result, research turned away from the perceptron. Then the pendulum swung back, and machine learning became the fastest-growing field in computer science. Minsky and Papert's insistence on its theoretical foundations is newly relevant.Perceptrons—the first systematic study of parallelism in computation—marked a historic turn in artificial intelligence, returning to the idea that intelligence might emerge from the activity of networks of neuron-like entities. Minsky and Papert provided mathematical analysis that showed the limitations of a class of computing machines that could be considered as models of the brain. Minsky and Papert added a new chapter in 1987 in which they discuss the state of parallel computers, and note a central theoretical challenge: reaching a deeper understanding of how “objects” or “agents” with individuality can emerge in a network. Progress in this area would link connectionism with what the authors have called “society theories of mind.”},
	pagetotal = {317},
	publisher = {{MIT} Press},
	author = {Minsky, Marvin and Papert, Seymour A.},
	date = {2017-09-22},
	langid = {english},
	note = {Google-Books-{ID}: {PLQ}5DwAAQBAJ},
	keywords = {Computers / Computer Science}
}

@book{cicchinelli_frank_1956,
	title = {Frank Rosenblatt publications.},
	abstract = {Cornell Aeronautical Laboratory publications by Frank Rosenblatt include " The Perceptron: A Theory of Statistical Separability in Cognitive Systems," January 1958; Research Trends: "The Design of an Intelligent Automaton," Summer 1958; "Technical Memorandum \#2, An Anaylsis of Very Large Perceptrons in a Finite Universe," October 1958; "Two Theories of Statistical Separability in the Perceptron", November 1958; and Cognitive Systems Research Program, Report No. 4 Collected Technical Papers Volume 2, July 30, 1963. Also mimeographs of "Digital Application Series No. 2, Control Engineering, January 1956, Solving Scientific Problems" and "Electronic Digital Machines," by A. I. Kitov, Government Publishing House, Moscow, 1956 (2 pp.). Also a list of publications by Rosenblatt.},
	author = {Cicchinelli, Alexander L and Rosenblatt, Frank and Kitov, A. I and {Cornell Aeronautical Laboratory}},
	date = {1956},
	note = {{OCLC}: 64057171}
}

@online{noauthor_perceptrons_nodate,
	title = {Perceptrons : Marvin L. Minsky : Free Download, Borrow, and Streaming : Internet Archive},
	url = {https://archive.org/details/Perceptrons},
	urldate = {2020-01-14},
	file = {Perceptrons \: Marvin L. Minsky \: Free Download, Borrow, and Streaming \: Internet Archive:/home/danielsan/Zotero/storage/UNK693T2/Perceptrons.html:text/html}
}

@article{brown_legacy_2003,
	title = {The legacy of Donald O. Hebb: more than the Hebb Synapse},
	volume = {4},
	rights = {2003 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1257},
	doi = {10.1038/nrn1257},
	shorttitle = {The legacy of Donald O. Hebb},
	abstract = {Neuroscientists associate the name of Donald O. Hebb with the Hebbian synapse and the Hebbian learning rule, which underlie connectionist theories and synaptic plasticity, but Hebb's work has also influenced developmental psychology, neuropsychology, perception and the study of emotions, as well as learning and memory. Here, we review the work of Hebb and its lasting influence on neuroscience in honour of the 2004 centenary of his birth.},
	pages = {1013--1019},
	number = {12},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Brown, Richard E. and Milner, Peter M.},
	urldate = {2020-01-14},
	date = {2003-12},
	langid = {english},
	file = {Snapshot:/home/danielsan/Zotero/storage/SUFMQ3I8/nrn1257.html:text/html}
}

@article{von_neumann_first_1993,
	title = {First draft of a report on the {EDVAC}},
	volume = {15},
	issn = {1934-1547},
	doi = {10.1109/85.238389},
	abstract = {The first draft of a report on the {EDVAC} written by John von Neumann is presented. This first draft contains a wealth of information, and it had a pervasive influence when it was first written. Most prominently, Alan Turing cites it in his proposal for the Pilot automatic computing engine ({ACE}) as the definitive source for understanding the nature and design of a general-purpose digital computer.{\textless}{\textgreater}},
	pages = {27--75},
	number = {4},
	journaltitle = {{IEEE} Annals of the History of Computing},
	author = {von Neumann, J.},
	date = {1993},
	keywords = {automatic computing engine, digital computers, {EDVAC}, Electrical engineering, Engines, Forward contracts, general-purpose digital computer, history, History, Laboratories, Mathematics, Pain, Physics computing, Proposals, Statistics},
	file = {IEEE Xplore Abstract Record:/home/danielsan/Zotero/storage/ZLITNL3J/238389.html:text/html}
}