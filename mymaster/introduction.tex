For the past 70 years, a myriad of researchers and developers has been on a quest for a manmade system that might replicate human function and behavior.
The development of autonomous systems has gotten so far that human function and behavior can be easily imitated, but only in a few use-cases at a time.
Several scientists and philosophers have proposed theories and tools to evaluate the level of intelligence of a system.
For example, Alan Touring proposed The Touring Test, inspired by the party game The Imitation Game, to assess whether a machine is intelligent \cite{computing_machine_intelligence_turing}.
Computer programs might contain autonomous functions that seem to stretch over such a broad field of capabilities,
that it might fool other agents for prolonged periods. However, with time, most illusions are broken.
In the search for artificial intelligence, new technologies are continuously being developed, and with them, new theories.

When the neuron was being explored, in the 1940s, a simple model computational model was developed to understand it, the McCulloch and Pitt's Neuron, or The Perceptron \cite{mculloch_pitts}.
The Perceptron is often connected in networks of multiple layers and connectivity types to form what we generally call Artificial Neural Networks (ANN) \cite{neural_network},
which have been proven useful in a wide plethora of use-cases. ANNs, in its various forms, are now the most used tool for developing modern artificial intelligence technologies.
As our understanding of neurobiology has progressed, more advanced models have been developed, including details of the ion flows and proteins that affect the membrane potential \cite{leaky_integrate_and_fire}.
These models are often called Leaky Integrate and Fire Neurons, and the neural networks are often called Spiking Neural Networks (SNN).

Even though our computational power has grown exponentially for 70 years, the efficiency of our systems do not apply to large simulations running SNNs \cite{moores_law}\cite{hpc_energy},
and a more suitable technology might be required, termed Neuromorphic Systems \cite{neuromorphic_systems}.
Today, the dominating computer architecture is the Von-Neumann architecture, urged forward by Alan Touring, amongst others \cite{imitation_game}.
Although the architecture has been proven to be very efficient for most computational tasks, but also very inefficient for intricate tasks that are easily solved by the biological systems.
When trying to solve these tasks on ordinary computers, the complexity and size of computational models are increasing so fast,
that the energy usage of computation has become a real environmental concern \cite{computation_energy_environment}.
As SNNs share more characteristics with biological neural networks, it is thought that they might provide the same intricate, low-cost solutions as biological systems do,
given the right hardware to operate on. For this, Neuromorphic Systems are being developed \cite{neuromorphic_systems}.

If a system can solve the same intricate tasks as a human, with ease, and also have a general behavior as a human,
it could likely pass The Touring Test, but would it then have a human level of intelligence?
Based on the plethora of theories regarding intelligence, that exist today, the answer could be both yes and no.
If a system was to have a human level of intelligence, one could argue that it would need to experience like a human.
Some scientists might question whether the system was conscious like a human, and draw parallels to the experience of the system \cite{tononi_iit3}.
The Integrated Information Theory (IIT) is one of many theories questioning consciousness and intelligence, and it provides mathematical tools
to assess information about the cognitive abilities of a system.

After unraveling the mystery of life, some scientists went on to question consciousness.
This term can be used with different meanings, but some philosophers argue that being conscious requires a subjective experience, and this meaning will be used in this essay.
If a system was to have a human level of intelligence, it would most likely need to have subjective experiences, and thus it would most likely need to be conscious.
Giulio Tononi has proposed IIT, with tools to evaluate the phenomenology of a causal structure, that is,
how well a system integrates information based on experiences. This might be a good tool to evaluate parts of the intelligence of a manmade system,
but the theory itself requires that a system is integrated. Most systems today that can be considered intelligent, are developed on traditional computers.
The problem with traditional computers is that they are not integrated, they are highly modular, with different parts completely fulfilling its own function.
Using IIT to evaluate the intelligence of a computer program with autonomous functionality, then seems to be useless.
However, some neuromorphic systems, built to resemble neural architecture, have more integrated architecture.
A program written for one of these systems might be considered conscious by IIT, and might lead to new insights in the requirements for creating a system with a human level of intelligence.
